{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2022-06-16 14:53:31.233789: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-large and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LABEL_0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification\n",
    "\n",
    "tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-large\")\n",
    "model = DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-large\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  \n",
       "0                Adequate  \n",
       "1                Adequate  \n",
       "2                Adequate  \n",
       "3                Adequate  \n",
       "4                Adequate  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Seeking multiple opinions can help a person ma...</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>it can decrease stress levels</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>a great chance to learn something new</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>can be very helpful and beneficial.</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  a261b6e14276  D72CB1C11673   \n",
       "1  5a88900e7dc1  D72CB1C11673   \n",
       "2  9790d835736b  D72CB1C11673   \n",
       "3  75ce6d68b67b  D72CB1C11673   \n",
       "4  93578d946723  D72CB1C11673   \n",
       "\n",
       "                                      discourse_text discourse_type  \n",
       "0  Making choices in life can be very difficult. ...           Lead  \n",
       "1  Seeking multiple opinions can help a person ma...       Position  \n",
       "2                     it can decrease stress levels           Claim  \n",
       "3             a great chance to learn something new           Claim  \n",
       "4               can be very helpful and beneficial.           Claim  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91B1F82B2CF1    23\n",
       "4CA37D113612    23\n",
       "900A879708F0    23\n",
       "A7EC6F462F8B    22\n",
       "DECAE402BB38    22\n",
       "                ..\n",
       "AB02689C1A9B     1\n",
       "FFFF80B8CC2F     1\n",
       "377548575048     1\n",
       "5E85F1FB4E22     1\n",
       "9706F8E7D534     1\n",
       "Name: essay_id, Length: 4191, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.essay_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25190</th>\n",
       "      <td>2d4def8e7c09</td>\n",
       "      <td>91B1F82B2CF1</td>\n",
       "      <td>Many people may think that attending school on...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25191</th>\n",
       "      <td>0a6634792991</td>\n",
       "      <td>91B1F82B2CF1</td>\n",
       "      <td>I would say that I disagree with that statemen...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25192</th>\n",
       "      <td>e73c3a854460</td>\n",
       "      <td>91B1F82B2CF1</td>\n",
       "      <td>Yes, online school would be better for student...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25193</th>\n",
       "      <td>57d92e1dddb3</td>\n",
       "      <td>91B1F82B2CF1</td>\n",
       "      <td>but what about in the future when they lack ba...</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25194</th>\n",
       "      <td>4e57f20c26e0</td>\n",
       "      <td>91B1F82B2CF1</td>\n",
       "      <td>yes, the online courses could be more personal...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       discourse_id      essay_id  \\\n",
       "25190  2d4def8e7c09  91B1F82B2CF1   \n",
       "25191  0a6634792991  91B1F82B2CF1   \n",
       "25192  e73c3a854460  91B1F82B2CF1   \n",
       "25193  57d92e1dddb3  91B1F82B2CF1   \n",
       "25194  4e57f20c26e0  91B1F82B2CF1   \n",
       "\n",
       "                                          discourse_text discourse_type  \\\n",
       "25190  Many people may think that attending school on...           Lead   \n",
       "25191  I would say that I disagree with that statemen...       Position   \n",
       "25192  Yes, online school would be better for student...   Counterclaim   \n",
       "25193  but what about in the future when they lack ba...       Rebuttal   \n",
       "25194  yes, the online courses could be more personal...   Counterclaim   \n",
       "\n",
       "      discourse_effectiveness  \n",
       "25190                Adequate  \n",
       "25191                Adequate  \n",
       "25192                Adequate  \n",
       "25193                Adequate  \n",
       "25194                Adequate  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.essay_id=='91B1F82B2CF1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import warnings,transformers,logging,torch\n",
    "from transformers import TrainingArguments,Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "# if not iskaggle:\n",
    "#     import zipfile,kaggle\n",
    "#     path = Path('feedback-prize-effectiveness')\n",
    "#     kaggle.api.competition_download_cli(str(path))\n",
    "#     zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
    "\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep = tokenizer.sep_token\n",
    "sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['inputs'] = df.discourse_type + sep +df.discourse_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_label = {\"discourse_effectiveness\": {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}}\n",
    "df = df.replace(new_label)\n",
    "df = df.rename(columns = {\"discourse_effectiveness\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tok_func(x): return tokenizer(x[\"inputs\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 32258, 2, 30086, 6, 939, 437, 12370, 6, 939, 437, 164, 7, 28, 2410, 59, 141, 42, 652, 15, 6507, 16, 10, 1632, 1212, 3899, 50, 114, 89, 16, 301, 15, 6507, 14, 156, 24, 4, 20, 527, 16, 59, 141, 6109, 362, 10, 2170, 9, 6507, 8, 10, 652, 21, 450, 15, 5, 5518, 4, 6109, 630, 75, 216, 114, 5, 1212, 3899, 21, 1412, 30, 301, 15, 6507, 6, 50, 114, 24, 16, 95, 10, 1632, 1212, 3899, 4, 1437, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_func(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tok_func at 0x7fd5d20d9af0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33176a1c4f8463aa9cc3796cbac0360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inps = \"discourse_text\",\"discourse_type\"\n",
    "tok_ds = ds.map(tok_func, batched=True, remove_columns=inps+('inputs','discourse_id','essay_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B5C606F0A883', 'FA4FE7706A1A', '37A77BEAD718', '0ED28D8A5EC4',\n",
       "       'F25BA634ADDD'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_ids = df.essay_id.unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(essay_ids)\n",
    "essay_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_prop = 0.2\n",
    "val_sz = int(len(essay_ids)*val_prop)\n",
    "val_essay_ids = essay_ids[:val_sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7181, 29584)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_val = np.isin(df.essay_id, val_essay_ids)\n",
    "idxs = np.arange(len(df))\n",
    "val_idxs = idxs[ is_val]\n",
    "trn_idxs = idxs[~is_val]\n",
    "len(val_idxs),len(trn_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dds = DatasetDict({\"train\":tok_ds.select(trn_idxs),\n",
    "             \"test\": tok_ds.select(val_idxs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_dds(df, train=True):\n",
    "    ds = Dataset.from_pandas(df)\n",
    "    ds.todevice=('cuda:0')\n",
    "    to_remove = ['discourse_text','discourse_type','inputs','discourse_id','essay_id']\n",
    "    tok_ds = ds.map(tok_func, batched=True, remove_columns=to_remove)\n",
    "    \n",
    "    if train:\n",
    "        return DatasetDict({\"train\":tok_ds.select(trn_idxs), \"test\": tok_ds.select(val_idxs)})\n",
    "    else: \n",
    "        return tok_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr,bs = 8e-5,16\n",
    "wd,epochs = 0.01,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import torch.nn.functional as F\n",
    "def score(preds): return {'log loss': log_loss(preds.label_ids, F.softmax(torch.Tensor(preds.predictions)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_trainer(dds):\n",
    "    args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "        evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "        num_train_epochs=epochs, weight_decay=wd, report_to='none')\n",
    "\n",
    "\n",
    "\n",
    "    model = DebertaForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-large\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model.to(device)\n",
    "\n",
    "    return Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                   tokenizer=tokenizer, compute_metrics=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-large and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 29584\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "innerLab03-Dell:966907:966907 [0] NCCL INFO Bootstrap : Using [0]eno4:192.168.0.138<0> [1]br-f27996258617:172.19.0.1<0> [2]br-6cb110c1c75c:172.21.0.1<0> [3]br-9887d1db9997:172.22.0.1<0> [4]veth3eb884a:fe80::e8d6:d6ff:fe95:4656%veth3eb884a<0> [5]vethda223e3:fe80::7009:86ff:fe3e:8cbb%vethda223e3<0> [6]veth565ff73:fe80::6c07:86ff:fe89:a597%veth565ff73<0> [7]veth9ca141a:fe80::d8fb:15ff:fe1a:4a87%veth9ca141a<0> [8]vethf8502bf:fe80::c8d7:53ff:fe5d:d039%vethf8502bf<0> [9]veth1ed4325:fe80::94d8:ecff:fef7:427%veth1ed4325<0> [10]vethc00f921:fe80::e854:65ff:fe67:2009%vethc00f921<0> [11]veth3fd2dca:fe80::841b:56ff:fe1a:398e%veth3fd2dca<0> [12]veth68f2179:fe80::b8e9:5cff:fe04:2721%veth68f2179<0> [13]vethbbe2260:fe80::c72:8ff:fe36:7aac%vethbbe2260<0> [14]veth29b2cfc:fe80::f42e:12ff:fe72:527d%veth29b2cfc<0> [15]veth72cbe3d:fe80::f0e8:55ff:fe83:93dd%veth72cbe3d<0>\n",
      "innerLab03-Dell:966907:966907 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
      "\n",
      "innerLab03-Dell:966907:966907 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\n",
      "innerLab03-Dell:966907:966907 [0] NCCL INFO NET/Socket : Using [0]eno4:192.168.0.138<0> [1]br-f27996258617:172.19.0.1<0> [2]br-6cb110c1c75c:172.21.0.1<0> [3]br-9887d1db9997:172.22.0.1<0> [4]veth3eb884a:fe80::e8d6:d6ff:fe95:4656%veth3eb884a<0> [5]vethda223e3:fe80::7009:86ff:fe3e:8cbb%vethda223e3<0> [6]veth565ff73:fe80::6c07:86ff:fe89:a597%veth565ff73<0> [7]veth9ca141a:fe80::d8fb:15ff:fe1a:4a87%veth9ca141a<0> [8]vethf8502bf:fe80::c8d7:53ff:fe5d:d039%vethf8502bf<0> [9]veth1ed4325:fe80::94d8:ecff:fef7:427%veth1ed4325<0> [10]vethc00f921:fe80::e854:65ff:fe67:2009%vethc00f921<0> [11]veth3fd2dca:fe80::841b:56ff:fe1a:398e%veth3fd2dca<0> [12]veth68f2179:fe80::b8e9:5cff:fe04:2721%veth68f2179<0> [13]vethbbe2260:fe80::c72:8ff:fe36:7aac%vethbbe2260<0> [14]veth29b2cfc:fe80::f42e:12ff:fe72:527d%veth29b2cfc<0> [15]veth72cbe3d:fe80::f0e8:55ff:fe83:93dd%veth72cbe3d<0>\n",
      "innerLab03-Dell:966907:966907 [0] NCCL INFO Using network Socket\n",
      "NCCL version 2.7.8+cuda10.2\n",
      "\n",
      "innerLab03-Dell:966907:968079 [2] misc/nvmlwrap.cc:115 NCCL WARN nvmlInit() failed: Driver/library version mismatch\n",
      "innerLab03-Dell:966907:968079 [2] NCCL INFO graph/xml.cc:662 -> 2\n",
      "innerLab03-Dell:966907:968079 [2] NCCL INFO graph/topo.cc:523 -> 2\n",
      "innerLab03-Dell:966907:968079 [2] NCCL INFO init.cc:581 -> 2\n",
      "innerLab03-Dell:966907:968079 [2] NCCL INFO init.cc:840 -> 2\n",
      "innerLab03-Dell:966907:968079 [2] NCCL INFO group.cc:73 -> 2 [Async thread]\n",
      "\n",
      "innerLab03-Dell:966907:968078 [1] misc/nvmlwrap.cc:115 NCCL WARN nvmlInit() failed: Driver/library version mismatch\n",
      "innerLab03-Dell:966907:968078 [1] NCCL INFO graph/xml.cc:662 -> 2\n",
      "innerLab03-Dell:966907:968078 [1] NCCL INFO graph/topo.cc:523 -> 2\n",
      "innerLab03-Dell:966907:968078 [1] NCCL INFO init.cc:581 -> 2\n",
      "innerLab03-Dell:966907:968078 [1] NCCL INFO init.cc:840 -> 2\n",
      "innerLab03-Dell:966907:968078 [1] NCCL INFO group.cc:73 -> 2 [Async thread]\n",
      "\n",
      "innerLab03-Dell:966907:968077 [0] misc/nvmlwrap.cc:115 NCCL WARN nvmlInit() failed: Driver/library version mismatch\n",
      "innerLab03-Dell:966907:968077 [0] NCCL INFO graph/xml.cc:662 -> 2\n",
      "innerLab03-Dell:966907:968077 [0] NCCL INFO graph/topo.cc:523 -> 2\n",
      "innerLab03-Dell:966907:968077 [0] NCCL INFO init.cc:581 -> 2\n",
      "innerLab03-Dell:966907:968077 [0] NCCL INFO init.cc:840 -> 2\n",
      "innerLab03-Dell:966907:968077 [0] NCCL INFO group.cc:73 -> 2 [Async thread]\n",
      "\n",
      "innerLab03-Dell:966907:968080 [3] misc/nvmlwrap.cc:115 NCCL WARN nvmlInit() failed: Driver/library version mismatch\n",
      "innerLab03-Dell:966907:968080 [3] NCCL INFO graph/xml.cc:662 -> 2\n",
      "innerLab03-Dell:966907:968080 [3] NCCL INFO graph/topo.cc:523 -> 2\n",
      "innerLab03-Dell:966907:968080 [3] NCCL INFO init.cc:581 -> 2\n",
      "innerLab03-Dell:966907:968080 [3] NCCL INFO init.cc:840 -> 2\n",
      "innerLab03-Dell:966907:968080 [3] NCCL INFO group.cc:73 -> 2 [Async thread]\n",
      "innerLab03-Dell:966907:966907 [0] NCCL INFO init.cc:906 -> 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NCCL Error 2: unhandled system error",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m/home/innerwave/ailab/YYC/dataset/FPE/FPE.ipynb Cell 26'\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binnerwave@192.168.0.138:22/home/innerwave/ailab/YYC/dataset/FPE/FPE.ipynb#ch0000024vscode-remote?line=0'>1</a>\u001B[0m trainer \u001B[39m=\u001B[39m get_trainer(dds)\n\u001B[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Binnerwave@192.168.0.138:22/home/innerwave/ailab/YYC/dataset/FPE/FPE.ipynb#ch0000024vscode-remote?line=1'>2</a>\u001B[0m trainer\u001B[39m.\u001B[39;49mtrain()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1317\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1312\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mmodel_wrapped \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mmodel\n\u001B[1;32m   1314\u001B[0m inner_training_loop \u001B[39m=\u001B[39m find_executable_batch_size(\n\u001B[1;32m   1315\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_inner_training_loop, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_train_batch_size, args\u001B[39m.\u001B[39mauto_find_batch_size\n\u001B[1;32m   1316\u001B[0m )\n\u001B[0;32m-> 1317\u001B[0m \u001B[39mreturn\u001B[39;00m inner_training_loop(\n\u001B[1;32m   1318\u001B[0m     args\u001B[39m=\u001B[39;49margs,\n\u001B[1;32m   1319\u001B[0m     resume_from_checkpoint\u001B[39m=\u001B[39;49mresume_from_checkpoint,\n\u001B[1;32m   1320\u001B[0m     trial\u001B[39m=\u001B[39;49mtrial,\n\u001B[1;32m   1321\u001B[0m     ignore_keys_for_eval\u001B[39m=\u001B[39;49mignore_keys_for_eval,\n\u001B[1;32m   1322\u001B[0m )\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1554\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1552\u001B[0m         tr_loss_step \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtraining_step(model, inputs)\n\u001B[1;32m   1553\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m-> 1554\u001B[0m     tr_loss_step \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtraining_step(model, inputs)\n\u001B[1;32m   1556\u001B[0m \u001B[39mif\u001B[39;00m (\n\u001B[1;32m   1557\u001B[0m     args\u001B[39m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   1558\u001B[0m     \u001B[39mand\u001B[39;00m \u001B[39mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[1;32m   1559\u001B[0m     \u001B[39mand\u001B[39;00m (torch\u001B[39m.\u001B[39misnan(tr_loss_step) \u001B[39mor\u001B[39;00m torch\u001B[39m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   1560\u001B[0m ):\n\u001B[1;32m   1561\u001B[0m     \u001B[39m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   1562\u001B[0m     tr_loss \u001B[39m+\u001B[39m\u001B[39m=\u001B[39m tr_loss \u001B[39m/\u001B[39m (\u001B[39m1\u001B[39m \u001B[39m+\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mstate\u001B[39m.\u001B[39mglobal_step \u001B[39m-\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2183\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   2180\u001B[0m     \u001B[39mreturn\u001B[39;00m loss_mb\u001B[39m.\u001B[39mreduce_mean()\u001B[39m.\u001B[39mdetach()\u001B[39m.\u001B[39mto(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39margs\u001B[39m.\u001B[39mdevice)\n\u001B[1;32m   2182\u001B[0m \u001B[39mwith\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mautocast_smart_context_manager():\n\u001B[0;32m-> 2183\u001B[0m     loss \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mcompute_loss(model, inputs)\n\u001B[1;32m   2185\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39margs\u001B[39m.\u001B[39mn_gpu \u001B[39m>\u001B[39m \u001B[39m1\u001B[39m:\n\u001B[1;32m   2186\u001B[0m     loss \u001B[39m=\u001B[39m loss\u001B[39m.\u001B[39mmean()  \u001B[39m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2215\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   2213\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m   2214\u001B[0m     labels \u001B[39m=\u001B[39m \u001B[39mNone\u001B[39;00m\n\u001B[0;32m-> 2215\u001B[0m outputs \u001B[39m=\u001B[39m model(\u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49minputs)\n\u001B[1;32m   2216\u001B[0m \u001B[39m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   2217\u001B[0m \u001B[39m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   2218\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39margs\u001B[39m.\u001B[39mpast_index \u001B[39m>\u001B[39m\u001B[39m=\u001B[39m \u001B[39m0\u001B[39m:\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m     result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_slow_forward(\u001B[39m*\u001B[39m\u001B[39minput\u001B[39m, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs)\n\u001B[1;32m    888\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m--> 889\u001B[0m     result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mforward(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m    890\u001B[0m \u001B[39mfor\u001B[39;00m hook \u001B[39min\u001B[39;00m itertools\u001B[39m.\u001B[39mchain(\n\u001B[1;32m    891\u001B[0m         _global_forward_hooks\u001B[39m.\u001B[39mvalues(),\n\u001B[1;32m    892\u001B[0m         \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks\u001B[39m.\u001B[39mvalues()):\n\u001B[1;32m    893\u001B[0m     hook_result \u001B[39m=\u001B[39m hook(\u001B[39mself\u001B[39m, \u001B[39minput\u001B[39m, result)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:166\u001B[0m, in \u001B[0;36mDataParallel.forward\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mlen\u001B[39m(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mdevice_ids) \u001B[39m==\u001B[39m \u001B[39m1\u001B[39m:\n\u001B[1;32m    165\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mmodule(\u001B[39m*\u001B[39minputs[\u001B[39m0\u001B[39m], \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs[\u001B[39m0\u001B[39m])\n\u001B[0;32m--> 166\u001B[0m replicas \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mreplicate(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mmodule, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mdevice_ids[:\u001B[39mlen\u001B[39;49m(inputs)])\n\u001B[1;32m    167\u001B[0m outputs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mparallel_apply(replicas, inputs, kwargs)\n\u001B[1;32m    168\u001B[0m \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mgather(outputs, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39moutput_device)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:171\u001B[0m, in \u001B[0;36mDataParallel.replicate\u001B[0;34m(self, module, device_ids)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mreplicate\u001B[39m(\u001B[39mself\u001B[39m, module, device_ids):\n\u001B[0;32m--> 171\u001B[0m     \u001B[39mreturn\u001B[39;00m replicate(module, device_ids, \u001B[39mnot\u001B[39;49;00m torch\u001B[39m.\u001B[39;49mis_grad_enabled())\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/replicate.py:91\u001B[0m, in \u001B[0;36mreplicate\u001B[0;34m(network, devices, detach)\u001B[0m\n\u001B[1;32m     89\u001B[0m params \u001B[39m=\u001B[39m \u001B[39mlist\u001B[39m(network\u001B[39m.\u001B[39mparameters())\n\u001B[1;32m     90\u001B[0m param_indices \u001B[39m=\u001B[39m {param: idx \u001B[39mfor\u001B[39;00m idx, param \u001B[39min\u001B[39;00m \u001B[39menumerate\u001B[39m(params)}\n\u001B[0;32m---> 91\u001B[0m param_copies \u001B[39m=\u001B[39m _broadcast_coalesced_reshape(params, devices, detach)\n\u001B[1;32m     93\u001B[0m buffers \u001B[39m=\u001B[39m \u001B[39mlist\u001B[39m(network\u001B[39m.\u001B[39mbuffers())\n\u001B[1;32m     94\u001B[0m buffers_rg \u001B[39m=\u001B[39m []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/replicate.py:71\u001B[0m, in \u001B[0;36m_broadcast_coalesced_reshape\u001B[0;34m(tensors, devices, detach)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m     \u001B[39m# Use the autograd function to broadcast if not detach\u001B[39;00m\n\u001B[1;32m     70\u001B[0m     \u001B[39mif\u001B[39;00m \u001B[39mlen\u001B[39m(tensors) \u001B[39m>\u001B[39m \u001B[39m0\u001B[39m:\n\u001B[0;32m---> 71\u001B[0m         tensor_copies \u001B[39m=\u001B[39m Broadcast\u001B[39m.\u001B[39;49mapply(devices, \u001B[39m*\u001B[39;49mtensors)\n\u001B[1;32m     72\u001B[0m         \u001B[39mreturn\u001B[39;00m [tensor_copies[i:i \u001B[39m+\u001B[39m \u001B[39mlen\u001B[39m(tensors)]\n\u001B[1;32m     73\u001B[0m                 \u001B[39mfor\u001B[39;00m i \u001B[39min\u001B[39;00m \u001B[39mrange\u001B[39m(\u001B[39m0\u001B[39m, \u001B[39mlen\u001B[39m(tensor_copies), \u001B[39mlen\u001B[39m(tensors))]\n\u001B[1;32m     74\u001B[0m     \u001B[39melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:23\u001B[0m, in \u001B[0;36mBroadcast.forward\u001B[0;34m(ctx, target_gpus, *inputs)\u001B[0m\n\u001B[1;32m     21\u001B[0m ctx\u001B[39m.\u001B[39mnum_inputs \u001B[39m=\u001B[39m \u001B[39mlen\u001B[39m(inputs)\n\u001B[1;32m     22\u001B[0m ctx\u001B[39m.\u001B[39minput_device \u001B[39m=\u001B[39m inputs[\u001B[39m0\u001B[39m]\u001B[39m.\u001B[39mget_device()\n\u001B[0;32m---> 23\u001B[0m outputs \u001B[39m=\u001B[39m comm\u001B[39m.\u001B[39;49mbroadcast_coalesced(inputs, ctx\u001B[39m.\u001B[39;49mtarget_gpus)\n\u001B[1;32m     24\u001B[0m non_differentiables \u001B[39m=\u001B[39m []\n\u001B[1;32m     25\u001B[0m \u001B[39mfor\u001B[39;00m idx, input_requires_grad \u001B[39min\u001B[39;00m \u001B[39menumerate\u001B[39m(ctx\u001B[39m.\u001B[39mneeds_input_grad[\u001B[39m1\u001B[39m:]):\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/comm.py:58\u001B[0m, in \u001B[0;36mbroadcast_coalesced\u001B[0;34m(tensors, devices, buffer_size)\u001B[0m\n\u001B[1;32m     56\u001B[0m devices \u001B[39m=\u001B[39m [_get_device_index(d) \u001B[39mfor\u001B[39;00m d \u001B[39min\u001B[39;00m devices]\n\u001B[1;32m     57\u001B[0m tensors \u001B[39m=\u001B[39m [_handle_complex(t) \u001B[39mfor\u001B[39;00m t \u001B[39min\u001B[39;00m tensors]\n\u001B[0;32m---> 58\u001B[0m \u001B[39mreturn\u001B[39;00m torch\u001B[39m.\u001B[39;49m_C\u001B[39m.\u001B[39;49m_broadcast_coalesced(tensors, devices, buffer_size)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: NCCL Error 2: unhandled system error"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(dds)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}