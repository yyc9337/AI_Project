{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "#### Setting\n",
    "\n",
    "        1. 1차 정제 데이터인 CAI_data_001.csv  데이터를 사용하여 2차 전처리 진행\n",
    "        2. >를 기준으로 depth 나눔\n",
    "        3. 모델링\n",
    "\n",
    "#### Method\n",
    "        \n",
    "        1. VOC 유형 중 depth_1 유형을 예측하는 모델\n",
    "        2. model 폴더에 pt파일로 모델 저장\n",
    "        3. 현재 모델(RoBERTa)과 LSTM의 비교\n",
    "        4. CompDataset class를 이용하여 데이터프레임을 입력하여 모델에 입력될 수 있도록 정제시킴\n",
    "\n",
    "#### Result\n",
    "        \n",
    "        Val loss: 70.25707527855411\n",
    "        Val acc:  0.8888888888888888\n",
    "\n",
    "#### Add\n",
    "        1. epoch 늘리기 (CPU구동할땐 10epoch이 14시간 걸림)\n",
    "        2. batch size \n",
    "        3. 4번째 셀에 MODEL_TYPE = 'xlm-roberta-base'에서 base가 large로 바뀌면 \n",
    "           더 큰 사전을 구축할 수 있음(지금은 노트북이 못버팀)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. RoBERTa는 KoBERT와 다르게 여러나라의 언어를 포함하고 있는 사전이 있어, 큰 용량을 차지함.\n",
    "2. 큰 용량임에도 불구하고 많은 사람들이 이용하는 이유는 그럼에도 좋은 성능이 나온다고 함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 라이브러리 설치\n",
    "#!pip install mxnet\n",
    "#!pip install gluonnlp\n",
    "#!pip install transformers\n",
    "#!pip install sentencepiece\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# seed 값 설정\n",
    "torch.manual_seed(555)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLM-RoBERTa 토크나이저를 불러옵니다: https://huggingface.co/xlm-roberta-large\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "\n",
    "MODEL_TYPE = 'xlm-roberta-base'\n",
    "# 만약 colab pro가 아니면 MODEL_TYPE = 'xlm-roberta-base'를 사용하세요\n",
    "# GPU를 사용하고 있다면 \"xlm-roberta-large\"  사용 추천\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XLM-RoBERTa vocab크기 확인\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0, 107687,      2,      2,      6,  57991,  58470,   5826,      5,\n",
      "             2,      1,      1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = encoded_dict['input_ids'][0]\n",
    "att_mask = encoded_dict['attention_mask'][0]\n",
    "\n",
    "print(input_ids)\n",
    "print(att_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU 확인\n",
    "# device 설정\n",
    "device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df set: 8186개\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"../data/dataset/CAI_data_001.csv\")\n",
    "print(\"df set: {}개\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>depth_1</th>\n",
       "      <th>depth_2</th>\n",
       "      <th>depth_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>원인불명&gt;조치 전 자연 회복</td>\n",
       "      <td>고객 요청사 항 안됨상담 중 자연회복됨</td>\n",
       "      <td>원인불명</td>\n",
       "      <td>조치 전 자연 회복</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>실시간 채널&gt;네트워크 오류</td>\n",
       "      <td>고객 요청사항 수신불인터넷 연결오류 뜸재부팅해 봄 모텔 영업용 일 중 꼭 점검원하여...</td>\n",
       "      <td>실시간 채널</td>\n",
       "      <td>네트워크 오류</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>실시간 채널&gt;수신 불량</td>\n",
       "      <td>고객 요청사항 수신불회선 단말특이사항 진단 결과 기타 추가 연락처 연후방</td>\n",
       "      <td>실시간 채널</td>\n",
       "      <td>수신 불량</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>실시간 채널&gt;네트워크 오류</td>\n",
       "      <td>수신 불 네트워크 오류 접수 보류</td>\n",
       "      <td>실시간 채널</td>\n",
       "      <td>네트워크 오류</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>실시간 채널&gt;수신 불량</td>\n",
       "      <td>고객 요청사항 수신불 연락 후 회선단말특이사항 진단 결과 기타 추가 연락처인 입</td>\n",
       "      <td>실시간 채널</td>\n",
       "      <td>수신 불량</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8181</th>\n",
       "      <td>실시간 채널&gt;화질 이상</td>\n",
       "      <td>안심권유 고객 요청사항 화질 불량 시청 중 화면 멈추고 꺼졌다 켜지는 현상이 있다고...</td>\n",
       "      <td>실시간 채널</td>\n",
       "      <td>화질 이상</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8182</th>\n",
       "      <td>원인불명&gt;조치 전 자연 회복</td>\n",
       "      <td>리콜 넷플릭스 연령 인증 문의 건 리콜하니 해결했다고 하심</td>\n",
       "      <td>원인불명</td>\n",
       "      <td>조치 전 자연 회복</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8183</th>\n",
       "      <td>실시간 채널&gt;수신 불량</td>\n",
       "      <td>고객 요청사항 대 수신불전송 후 리셋</td>\n",
       "      <td>실시간 채널</td>\n",
       "      <td>수신 불량</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184</th>\n",
       "      <td>실시간 채널&gt;네트워크 오류</td>\n",
       "      <td>안심권 유 빠른 점검 요청 고객 요청사항 시청 불인터넷 연결 오류 나 옴 모든 장비...</td>\n",
       "      <td>실시간 채널</td>\n",
       "      <td>네트워크 오류</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8185</th>\n",
       "      <td>단말&gt;STB(작동)이상</td>\n",
       "      <td>고객 요청사항 수신불 연락 후 방문 지니셋탑 전원안 들어옴 교체 요청 회선 단말특이...</td>\n",
       "      <td>단말</td>\n",
       "      <td>STB(작동)이상</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8186 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Label                                           sentence  \\\n",
       "0     원인불명>조치 전 자연 회복                              고객 요청사 항 안됨상담 중 자연회복됨   \n",
       "1      실시간 채널>네트워크 오류  고객 요청사항 수신불인터넷 연결오류 뜸재부팅해 봄 모텔 영업용 일 중 꼭 점검원하여...   \n",
       "2        실시간 채널>수신 불량           고객 요청사항 수신불회선 단말특이사항 진단 결과 기타 추가 연락처 연후방   \n",
       "3      실시간 채널>네트워크 오류                                 수신 불 네트워크 오류 접수 보류   \n",
       "4        실시간 채널>수신 불량       고객 요청사항 수신불 연락 후 회선단말특이사항 진단 결과 기타 추가 연락처인 입   \n",
       "...               ...                                                ...   \n",
       "8181     실시간 채널>화질 이상  안심권유 고객 요청사항 화질 불량 시청 중 화면 멈추고 꺼졌다 켜지는 현상이 있다고...   \n",
       "8182  원인불명>조치 전 자연 회복                   리콜 넷플릭스 연령 인증 문의 건 리콜하니 해결했다고 하심   \n",
       "8183     실시간 채널>수신 불량                               고객 요청사항 대 수신불전송 후 리셋   \n",
       "8184   실시간 채널>네트워크 오류  안심권 유 빠른 점검 요청 고객 요청사항 시청 불인터넷 연결 오류 나 옴 모든 장비...   \n",
       "8185     단말>STB(작동)이상  고객 요청사항 수신불 연락 후 방문 지니셋탑 전원안 들어옴 교체 요청 회선 단말특이...   \n",
       "\n",
       "     depth_1     depth_2 depth_3  \n",
       "0       원인불명  조치 전 자연 회복     NaN  \n",
       "1     실시간 채널     네트워크 오류     NaN  \n",
       "2     실시간 채널       수신 불량     NaN  \n",
       "3     실시간 채널     네트워크 오류     NaN  \n",
       "4     실시간 채널       수신 불량     NaN  \n",
       "...      ...         ...     ...  \n",
       "8181  실시간 채널       화질 이상     NaN  \n",
       "8182    원인불명  조치 전 자연 회복     NaN  \n",
       "8183  실시간 채널       수신 불량     NaN  \n",
       "8184  실시간 채널     네트워크 오류     NaN  \n",
       "8185      단말   STB(작동)이상     NaN  \n",
       "\n",
       "[8186 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['depth_1'] = df.Label.str.split('>').str[0]\n",
    "df['depth_2'] = df.Label.str.split('>').str[1]\n",
    "df['depth_3'] = df.Label.str.split('>').str[2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11  9  9 ...  9  9  3]\n",
      "['AS접수/변경' 'VOD/컨텐츠' '고객원인' '단말' '데이터서비스' '리콜/손해배상' '부가/지능망서비스' '시설관리'\n",
      " '시설이전' '실시간 채널' '양방향서비스' '원인불명' '장애안내' '지니뮤직']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "result = le.fit_transform(df['depth_1'])\n",
    "print(result)\n",
    "print(le.classes_)\n",
    "\n",
    "df['depth_1'] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>depth_1</th>\n",
       "      <th>depth_2</th>\n",
       "      <th>depth_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>원인불명&gt;조치 전 자연 회복</td>\n",
       "      <td>고객 요청사 항 안됨상담 중 자연회복됨</td>\n",
       "      <td>11</td>\n",
       "      <td>조치 전 자연 회복</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>실시간 채널&gt;네트워크 오류</td>\n",
       "      <td>고객 요청사항 수신불인터넷 연결오류 뜸재부팅해 봄 모텔 영업용 일 중 꼭 점검원하여...</td>\n",
       "      <td>9</td>\n",
       "      <td>네트워크 오류</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>실시간 채널&gt;수신 불량</td>\n",
       "      <td>고객 요청사항 수신불회선 단말특이사항 진단 결과 기타 추가 연락처 연후방</td>\n",
       "      <td>9</td>\n",
       "      <td>수신 불량</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>실시간 채널&gt;네트워크 오류</td>\n",
       "      <td>수신 불 네트워크 오류 접수 보류</td>\n",
       "      <td>9</td>\n",
       "      <td>네트워크 오류</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>실시간 채널&gt;수신 불량</td>\n",
       "      <td>고객 요청사항 수신불 연락 후 회선단말특이사항 진단 결과 기타 추가 연락처인 입</td>\n",
       "      <td>9</td>\n",
       "      <td>수신 불량</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label                                           sentence  \\\n",
       "0  원인불명>조치 전 자연 회복                              고객 요청사 항 안됨상담 중 자연회복됨   \n",
       "1   실시간 채널>네트워크 오류  고객 요청사항 수신불인터넷 연결오류 뜸재부팅해 봄 모텔 영업용 일 중 꼭 점검원하여...   \n",
       "2     실시간 채널>수신 불량           고객 요청사항 수신불회선 단말특이사항 진단 결과 기타 추가 연락처 연후방   \n",
       "3   실시간 채널>네트워크 오류                                 수신 불 네트워크 오류 접수 보류   \n",
       "4     실시간 채널>수신 불량       고객 요청사항 수신불 연락 후 회선단말특이사항 진단 결과 기타 추가 연락처인 입   \n",
       "\n",
       "   depth_1     depth_2 depth_3  \n",
       "0       11  조치 전 자연 회복     NaN  \n",
       "1        9     네트워크 오류     NaN  \n",
       "2        9       수신 불량     NaN  \n",
       "3        9     네트워크 오류     NaN  \n",
       "4        9       수신 불량     NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7367\n",
      "819\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_dataset, val_dataset = train_test_split(df, test_size = 0.1)\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>depth_1</th>\n",
       "      <th>depth_2</th>\n",
       "      <th>depth_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>실시간 채널&gt;수신 불량</td>\n",
       "      <td>코로나 이 상무 고객 요청사항 대중안방수신 불방문해서 점검 요청회선 단말특이사항 진...</td>\n",
       "      <td>9</td>\n",
       "      <td>수신 불량</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>실시간 채널&gt;화질 이상</td>\n",
       "      <td>요청사항 화면 안 나옴 음성 정상셋 탑재부팅해도 동일 방문 시간 참고</td>\n",
       "      <td>9</td>\n",
       "      <td>화질 이상</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>단말&gt;리모컨작동불가&gt;현장출동</td>\n",
       "      <td>고객 요청사항 리모컨 작동 불가누르지 않아도 채널이 이동될 떄가 있다고 하심 전원도...</td>\n",
       "      <td>3</td>\n",
       "      <td>리모컨작동불가</td>\n",
       "      <td>현장출동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>실시간 채널&gt;수신 불량</td>\n",
       "      <td>코로나 이 상무재확인 필 고객 요청사항 시청 불 다른 것으로 교체해서 시청 중 원래...</td>\n",
       "      <td>9</td>\n",
       "      <td>수신 불량</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AS접수/변경&gt;장비리셋 후 재사용 요청</td>\n",
       "      <td>고객 요청사항리셋 접수 수신 불회선 단말특이사항 진단 결과 기타 추가 연락처</td>\n",
       "      <td>0</td>\n",
       "      <td>장비리셋 후 재사용 요청</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>원인불명&gt;조치 전 자연 회복</td>\n",
       "      <td>재부팅 후 사용 가능 고객 요청사항 회선 단말특이사항 진단 결과 기타 추가 연락처</td>\n",
       "      <td>11</td>\n",
       "      <td>조치 전 자연 회복</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>단말&gt;음성인식이상(기가지니)</td>\n",
       "      <td>일 시기가 지니 출도 안 했는데 혼자서 말하고 기가 지니 소리가 혼자서 커졌다 작아...</td>\n",
       "      <td>3</td>\n",
       "      <td>음성인식이상(기가지니)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>단말&gt;음성인식이상(기가지니)</td>\n",
       "      <td>기가 지니 음성인식 안됨 네 소리에서 띵소리로 변경됨</td>\n",
       "      <td>3</td>\n",
       "      <td>음성인식이상(기가지니)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>실시간 채널&gt;수신 불량</td>\n",
       "      <td>고객 요청사항 티비신없음 리셋 안내함 코로나 안내 회선단말특이사항 진단 결과 기타 ...</td>\n",
       "      <td>9</td>\n",
       "      <td>수신 불량</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>단말&gt;STB(작동)이상</td>\n",
       "      <td>시기가 지니 전원 버튼 작동 불전원 버튼 누르고 있어야만 불 들어옴 손떼면 꺼짐</td>\n",
       "      <td>3</td>\n",
       "      <td>STB(작동)이상</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>819 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Label                                           sentence  \\\n",
       "0             실시간 채널>수신 불량  코로나 이 상무 고객 요청사항 대중안방수신 불방문해서 점검 요청회선 단말특이사항 진...   \n",
       "1             실시간 채널>화질 이상             요청사항 화면 안 나옴 음성 정상셋 탑재부팅해도 동일 방문 시간 참고   \n",
       "2          단말>리모컨작동불가>현장출동  고객 요청사항 리모컨 작동 불가누르지 않아도 채널이 이동될 떄가 있다고 하심 전원도...   \n",
       "3             실시간 채널>수신 불량  코로나 이 상무재확인 필 고객 요청사항 시청 불 다른 것으로 교체해서 시청 중 원래...   \n",
       "4    AS접수/변경>장비리셋 후 재사용 요청         고객 요청사항리셋 접수 수신 불회선 단말특이사항 진단 결과 기타 추가 연락처   \n",
       "..                     ...                                                ...   \n",
       "814        원인불명>조치 전 자연 회복      재부팅 후 사용 가능 고객 요청사항 회선 단말특이사항 진단 결과 기타 추가 연락처   \n",
       "815        단말>음성인식이상(기가지니)  일 시기가 지니 출도 안 했는데 혼자서 말하고 기가 지니 소리가 혼자서 커졌다 작아...   \n",
       "816        단말>음성인식이상(기가지니)                      기가 지니 음성인식 안됨 네 소리에서 띵소리로 변경됨   \n",
       "817           실시간 채널>수신 불량  고객 요청사항 티비신없음 리셋 안내함 코로나 안내 회선단말특이사항 진단 결과 기타 ...   \n",
       "818           단말>STB(작동)이상       시기가 지니 전원 버튼 작동 불전원 버튼 누르고 있어야만 불 들어옴 손떼면 꺼짐   \n",
       "\n",
       "     depth_1        depth_2 depth_3  \n",
       "0          9          수신 불량     NaN  \n",
       "1          9          화질 이상     NaN  \n",
       "2          3        리모컨작동불가    현장출동  \n",
       "3          9          수신 불량     NaN  \n",
       "4          0  장비리셋 후 재사용 요청     NaN  \n",
       "..       ...            ...     ...  \n",
       "814       11     조치 전 자연 회복     NaN  \n",
       "815        3   음성인식이상(기가지니)     NaN  \n",
       "816        3   음성인식이상(기가지니)     NaN  \n",
       "817        9          수신 불량     NaN  \n",
       "818        3      STB(작동)이상     NaN  \n",
       "\n",
       "[819 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataloader에서 오류가 나서 인덱스 재설정\n",
    "train_dataset.index=[i for i in range(len(train_dataset))]\n",
    "val_dataset.index=[i for i in range(len(val_dataset))]\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val에 사용\n",
    "class CompDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df_data = df\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # 데이터프레임 칼럼 들고오기\n",
    "        sentence = self.df_data.loc[index, 'sentence']\n",
    "\n",
    "\n",
    "\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                    sentence,          \n",
    "                    add_special_tokens = True,      \n",
    "                    max_length = MAX_LEN,           \n",
    "                    pad_to_max_length = True,\n",
    "                    truncation=True,\n",
    "                    return_attention_mask = True,   \n",
    "                    return_tensors = 'pt',          \n",
    "               )\n",
    "        \n",
    "        padded_token_list = encoded_dict['input_ids'][0]\n",
    "        att_mask = encoded_dict['attention_mask'][0]\n",
    "        \n",
    "        # 숫자로 변환된 label을 텐서로 변환\n",
    "        target = torch.tensor(self.df_data.loc[index, 'depth_1'])\n",
    "        # input_ids, attention_mask, label을 하나의 인풋으로 묶음\n",
    "        sample = (padded_token_list, att_mask, target)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 하이퍼파라미터\n",
    "\n",
    "L_RATE = 1e-5 \n",
    "MAX_LEN = 100 \n",
    "\n",
    "BATCH_SIZE = 8 # batch size가 클수록 global minimum에 도달하는 속도가 증가합니다. (GPU 메모리에 따라 변경해 주세요, 너무 크면 OOM 문제가 발생합니다.)\n",
    "NUM_CORES = os.cpu_count() # Dataloader에 사용됩니다. \n",
    "\n",
    "NUM_CORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=14, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "    MODEL_TYPE, \n",
    "    num_labels = 14, # 출력 label의 개수\n",
    ")\n",
    "\n",
    "# model을 device위에 올림\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer 설정\n",
    "optimizer = AdamW(model.parameters(),\n",
    "              lr = L_RATE, \n",
    "              eps = 1e-8 \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "train_data = CompDataset(train_dataset)\n",
    "val_data = CompDataset(val_dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# batch_size 만큼 데이터 분할\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0)\n",
    "\n",
    "val_dataloader = DataLoader(val_data,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "Train loss: 1008.318221449852\n",
      "\n",
      "Validation...\n",
      "Val loss: 73.93006584048271\n",
      "Val acc:  0.8070818070818071\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "Train loss: 586.219025760889\n",
      "\n",
      "Validation...\n",
      "Val loss: 66.4939667955041\n",
      "Val acc:  0.8278388278388278\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "Train loss: 476.22105411347\n",
      "\n",
      "Validation...\n",
      "Val loss: 58.85903475852683\n",
      "Val acc:  0.8693528693528694\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "Train loss: 432.7693881522864\n",
      "\n",
      "Validation...\n",
      "Val loss: 61.7834887271747\n",
      "Val acc:  0.873015873015873\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "Train loss: 361.9174917093478\n",
      "\n",
      "Validation...\n",
      "Val loss: 58.87978678685613\n",
      "Val acc:  0.8852258852258852\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "Train loss: 318.1285489220172\n",
      "\n",
      "Validation...\n",
      "Val loss: 54.94982001069002\n",
      "Val acc:  0.8937728937728938\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "Train loss: 280.9448131811805\n",
      "\n",
      "Validation...\n",
      "Val loss: 59.62415628193412\n",
      "Val acc:  0.8913308913308914\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "Train loss: 249.8733259383589\n",
      "\n",
      "Validation...\n",
      "Val loss: 62.82539070933126\n",
      "Val acc:  0.9010989010989011\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "Train loss: 212.59691920655314\n",
      "\n",
      "Validation...\n",
      "Val loss: 66.67807807121426\n",
      "Val acc:  0.8962148962148963\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "Train loss: 189.53191635478288\n",
      "\n",
      "Validation...\n",
      "Val loss: 70.25707527855411\n",
      "Val acc:  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# 학습 횟수\n",
    "NUM_EPOCHS=10\n",
    "\n",
    "# loss값 저장\n",
    "loss_values = []\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    stacked_val_labels = []\n",
    "    targets_list = []\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print('Training...')\n",
    "    \n",
    "    # train mode 변환\n",
    "    model.train()\n",
    "    # True로 설정하게 되면 해당 텐서에서 어떤 연산이 이루어졌는지 추적할 수 있고, 해당 텐서에 대한 그라디언트를 저장하게 됩니다. \n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "\n",
    "    # 1epoch마다 loss값 초기화\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        train_status = 'Batch ' + str(i) + ' of ' + str(len(train_dataloader))\n",
    "        \n",
    "        print(train_status, end='\\r')\n",
    "\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device).long()\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # 3개의 인풋\n",
    "        outputs = model(b_input_ids, \n",
    "                    attention_mask=b_input_mask,\n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # outputs tuple: (loss, logits)\n",
    "        loss = outputs[0]\n",
    "        \n",
    "        # loss는 텐서이기 때문에 숫자로 변환 후 더합니다. \n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "        \n",
    "        # backward()를 하기 전에 optimizer의 그라디언트를 0으로 합니다. \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 그라디언트 계산\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        # \"exploding gradients\" 문제를 예방해줍니다.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        \n",
    "        # optimizer 가중치 업데이트\n",
    "        optimizer.step() \n",
    "    \n",
    "    print('Train loss:' ,total_train_loss)\n",
    "\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    \n",
    "    print('\\nValidation...')\n",
    "\n",
    "    # evaluation mode로 변환\n",
    "    model.eval()\n",
    "\n",
    "    # validation 과정에서는 그라디언트를 연산하거나 저장하지 않습니다.(메모리, 진행 속도 세이브)\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    total_val_loss = 0\n",
    "    \n",
    "\n",
    "    for j, batch in enumerate(val_dataloader):\n",
    "        \n",
    "        val_status = 'Batch ' + str(j) + ' of ' + str(len(val_dataloader))\n",
    "        \n",
    "        print(val_status, end='\\r')\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device).long()   \n",
    "\n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                attention_mask=b_input_mask, \n",
    "                labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        \n",
    "        total_val_loss = total_val_loss + loss.item()\n",
    "        \n",
    "\n",
    "        # 예측값\n",
    "        preds = outputs[1]\n",
    "\n",
    "\n",
    "        # 예측값을 CPU로 이동시킵니다. \n",
    "        val_preds = preds.detach().cpu().numpy()\n",
    "        \n",
    "        # labels을 cpu로 이동시킵니다.\n",
    "        targets_np = b_labels.to('cpu').numpy()\n",
    "\n",
    "        targets_list.extend(targets_np)\n",
    "\n",
    "        if j == 0:  # 첫 번째 batch일 떄\n",
    "            stacked_val_preds = val_preds\n",
    "\n",
    "        else:\n",
    "            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    # validation accuracy 계산\n",
    "    y_true = targets_list\n",
    "    y_pred = np.argmax(stacked_val_preds, axis=1)\n",
    "    \n",
    "    val_acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "    print('Val loss:' ,total_val_loss)\n",
    "    print('Val acc: ', val_acc)\n",
    "\n",
    "\n",
    "    # 모델 저장\n",
    "    torch.save(model.state_dict(), '../model/RoBERTa:{}_model.pt'.format(epoch))\n",
    "    \n",
    "    # 메모리 관리\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 불러오기 (선택)\n",
    "from transformers import XLMRobertaForSequenceClassification\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "    MODEL_TYPE, \n",
    "    num_labels = 14, \n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('../model/RoBERTa:1_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 70.25707527855411\n",
      "Val acc:  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "    print('Val loss:' ,total_val_loss)\n",
    "    print('Val acc: ', val_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40491703f7e3745db3ce67d00e0fd6bf66b5c9e5dc3c07d110e0729837b90781"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
