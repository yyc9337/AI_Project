{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc; gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zipfile.ZipFile('data/train_agg.pkl.zip').extract('train_agg.pkl')\n",
    "zipfile.ZipFile('data/test_agg.pkl.zip').extract('test_agg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"train_agg.pkl\", compression=\"gzip\")\n",
    "test = pd.read_pickle('test_agg.pkl', compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test.columns:\n",
    "    if test[col].dtype=='float16':\n",
    "        train[col] = train[col].astype('float32').round(decimals=2).astype('float16')\n",
    "        test[col] = test[col].astype('float32').round(decimals=2).astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = test.columns.to_list()\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "le_encoder = LabelEncoder()\n",
    "for categorical_feature in cat_features:\n",
    "    train[categorical_feature] = le_encoder.fit_transform(train[categorical_feature])\n",
    "    test[categorical_feature] = le_encoder.transform(test[categorical_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x == 0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "\n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x == 0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.DataFrame(train[\"target\"])\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_x, train_y, test_size=0.3, random_state=777, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import TPESampler\n",
    "\n",
    "sampler = TPESampler(seed=10)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 1024, step=1, log=True), \n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15, step=1, log=False), \n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.00001, 0.1, log=True), \n",
    "        'n_estimators': trial.suggest_int('n_estimators', 8, 3000, step=1, log=True), \n",
    "        'objective': 'multiclass', \n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50, step=1, log=False), \n",
    "        'subsample': trial.suggest_uniform('subsample', 0.4, 1.0), \n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 10.0),\n",
    "        'random_state': 0\n",
    "    }\n",
    "    model = lgb.LGBMClassifier(**param)\n",
    "    lgb_model = model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0, early_stopping_rounds=25)\n",
    "    amex_metric = amex_metric(lgb_model.predict(X_valid), y_valid)\n",
    "    return amex_metric\n",
    "        \n",
    "study_lgb = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study_lgb.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
