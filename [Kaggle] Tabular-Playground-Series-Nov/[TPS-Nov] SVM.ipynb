{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[TPS-Nov] SVM.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPezw4KtyQZZRNyrfcbnjMZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"daALMqkcoWap","executionInfo":{"status":"ok","timestamp":1637203777705,"user_tz":-540,"elapsed":449,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import LinearSVC\n","from sklearn.pipeline import make_pipeline\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n","from sklearn.metrics import precision_recall_fscore_support"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUNNshEnoaHL","executionInfo":{"status":"ok","timestamp":1637203059236,"user_tz":-540,"elapsed":14919,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"4f95edaf-3255-4151-f78c-e42a67595530"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"iVow4apS4yL8","executionInfo":{"status":"ok","timestamp":1637204414484,"user_tz":-540,"elapsed":270,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}}},"source":["def postprocess_separate(submission_df, test_df=None, pure_df=None):\n","    \"\"\"Update submission_df so that the predictions for the two sides of the hyperplane don't overlap.\n","    \n","    Parameters\n","    ----------\n","    submission_df : pandas DataFrame with columns 'id' and 'target'\n","    test_df : the competition's test data\n","    pure_df : the competition's original training data\n","    \n","    From https://www.kaggle.com/ambrosm/tpsnov21-007-postprocessing\n","    \"\"\"\n","    if pure_df is None: pure_df = pd.read_csv('/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/train.csv')\n","    if pure_df.shape != (600000, 102): raise ValueError(\"pure_df has the wrong shape\")\n","    if test_df is None: test_df = pd.read_csv('/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/test.csv')\n","    if test_df.shape[0] != submission_df.shape[0] or test_df.shape[1] != 101: raise ValueError(\"test_df has the wrong shape\")\n","\n","    # Find the separating hyperplane for pure_df, step 1\n","    # Use an SVM with almost no regularization\n","    model1 = make_pipeline(StandardScaler(), LinearSVC(C=1e5, tol=1e-7, penalty='l2', dual=False, max_iter=2000, random_state=1))\n","    model1.fit(pure_df.drop(columns=['id', 'target']), pure_df.target)\n","    pure_pred = model1.predict(pure_df.drop(columns=['id', 'target']))\n","    print((pure_pred != pure_df.target).sum(), (pure_pred == pure_df.target).sum()) # 1 599999\n","    # model1 is not perfect: it predicts the wrong class for 1 of 600000 samples\n","\n","    # Find the separating hyperplane for pure_df, step 2\n","    # Fit a second SVM to a subset of the points which contains the support vectors\n","    pure_pred = model1.decision_function(pure_df.drop(columns=['id', 'target']))\n","    subset_df = pure_df[(pure_pred > -5) & (pure_pred < 0.9)]\n","    model2 = make_pipeline(StandardScaler(), LinearSVC(C=1e5, tol=1e-7, penalty='l2', dual=False, max_iter=2000, random_state=1))\n","    model2.fit(subset_df.drop(columns=['id', 'target']), subset_df.target)\n","    pure_pred = model2.predict(pure_df.drop(columns=['id', 'target']))\n","    print((pure_pred != pure_df.target).sum(), (pure_pred == pure_df.target).sum()) # 0 600000\n","    # model2 is perfect: it predicts the correct class for all 600000 training samples\n","    \n","    pure_test_pred = model2.predict(test_df.drop(columns=['id', 'target'], errors='ignore'))\n","    lmax, rmin = sub[pure_test_pred == 0].target.max(), sub[pure_test_pred == 1].target.min()\n","    if lmax < rmin:\n","        print(\"There is no overlap. No postprocessing needed.\")\n","        return\n","    # There is overlap. Remove this overlap\n","    sub.loc[pure_test_pred == 0, 'target'] -= lmax + 1\n","    sub.loc[pure_test_pred == 1, 'target'] -= rmin - 1\n","    print(sub[pure_test_pred == 0].target.min(), sub[pure_test_pred == 0].target.max(),\n","          sub[pure_test_pred == 1].target.min(), sub[pure_test_pred == 1].target.max())\n","    \n","\n","\n"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":715},"id":"jM3PiASr6GRC","executionInfo":{"status":"ok","timestamp":1637204450936,"user_tz":-540,"elapsed":35198,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"7ecf413d-36ed-4e20-e8f0-c66fc59b6d32"},"source":["sub = pd.read_csv('/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/sample_submission.csv')\n","postprocess_separate(sub)\n","sub.to_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/svm_statistic_sub\", index=False)\n","sub.head(20)"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["157559 442441\n","157657 442343\n","-1.0 -1.0 1.0 1.0\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>600000</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>600001</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>600002</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>600003</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>600004</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>600005</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>600006</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>600007</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>600008</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>600009</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>600010</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>600011</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>600012</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>600013</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>600014</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>600015</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>600016</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>600017</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>600018</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>600019</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id  target\n","0   600000     1.0\n","1   600001     1.0\n","2   600002     1.0\n","3   600003    -1.0\n","4   600004     1.0\n","5   600005    -1.0\n","6   600006    -1.0\n","7   600007     1.0\n","8   600008     1.0\n","9   600009    -1.0\n","10  600010     1.0\n","11  600011     1.0\n","12  600012    -1.0\n","13  600013    -1.0\n","14  600014    -1.0\n","15  600015    -1.0\n","16  600016     1.0\n","17  600017    -1.0\n","18  600018     1.0\n","19  600019     1.0"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"eOxurmmy-XiG"},"source":["    print('정확도(accuracy_score) : ', accuracy_score(subset_df.target, pure_pred))\n","    print('정밀도(precision_score) : ', precision_score(subset_df.target, pure_pred))\n","    print('재현율(recall_score) : ', recall_score(subset_df.target, pure_pred))\n","    print('F1 : ', f1_score(subset_df.target, pure_pred))\n","    print('AUC : ', roc_auc_score(subset_df.target, pure_pred))\n","\n","    x = np.array([accuracy_score(subset_df.target, pure_pred),\n","              precision_score(subset_df.target, pure_pred),\n","              recall_score(subset_df.target, pure_pred),\n","              f1_score(subset_df.target, pure_pred),\n","              roc_auc_score(subset_df.target, pure_pred)])\n","    \n","    label = ['accuracy', 'precision', 'recall_score', 'f1_score', 'roc_auc']\n","\n","    index = np.arange(len(label))\n","\n","\n","    plt.bar(index, x, width=0.5)\n","    plt.title('evaluation index', fontsize=20)\n","    plt.ylabel('%', fontsize=18)\n","    plt.xticks(index, label, fontsize=15,rotation=90)    # X축의 범위: [xmin, xmax]\n","    plt.ylim([0, 1])     # Y축의 범위: [ymin, ymax]\n","    plt.show()\n"],"execution_count":null,"outputs":[]}]}