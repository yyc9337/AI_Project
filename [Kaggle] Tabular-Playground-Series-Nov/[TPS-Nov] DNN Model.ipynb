{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"[TPS-Nov] DNN Model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyM1PZ5Hg5+WbDL5de6cyxSl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"eFTvciCRow9M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637209063019,"user_tz":-540,"elapsed":14457,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"a30ff5dd-c5ed-4eb7-a360-eb0822f867be"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import statsmodels.api as sm\n","import torch\n","import gc\n","import torch.nn as nn\n","from sklearn.model_selection import StratifiedKFold\n","import seaborn as sns\n","\n","from tqdm import tqdm\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}]},{"cell_type":"markdown","metadata":{"id":"jB_s1jQUA1m7"},"source":["# Import Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ouWLNDN_APUp","executionInfo":{"status":"ok","timestamp":1637208932197,"user_tz":-540,"elapsed":16442,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"db1681e7-1f9e-4b22-c888-6ed6394da067"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"j_ch_EFfAQZo","executionInfo":{"status":"ok","timestamp":1637209083670,"user_tz":-540,"elapsed":20259,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}}},"source":["train = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/train.csv\")\n","test = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/test.csv\")\n","ss = pd.read_csv('/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/submission.csv')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"nsKuZ9AHAZZ4","executionInfo":{"status":"ok","timestamp":1637209245032,"user_tz":-540,"elapsed":461,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}}},"source":["train_df = train.drop(['id','f2','f35','f44','target'], axis = 1 )\n","test_df = test.drop(['id','f2','f35','f44'], axis = 1)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C3ZJm6TvA77I"},"source":["# EDA-1 세제곱근 씌워서 파생 변수 창출"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sQzTCC-A7X7","executionInfo":{"status":"ok","timestamp":1637209246489,"user_tz":-540,"elapsed":408,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"f4f9c450-d268-445e-96d9-a089791d11fc"},"source":["train.isnull().sum()[train.isnull().sum() != 0]"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Series([], dtype: int64)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4BrnGXgAaSD","executionInfo":{"status":"ok","timestamp":1637209247572,"user_tz":-540,"elapsed":6,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"2a2d1d10-4a9d-44bf-b3b5-f4be44575499"},"source":["features = test_df.columns.tolist()\n","len(features)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["97"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"1rCj6fEgAaui","executionInfo":{"status":"ok","timestamp":1637209412826,"user_tz":-540,"elapsed":150468,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"334c01b2-34dc-41cc-8735-df6e9178abd5"},"source":["for col in tqdm(features):\n","    train_df[col+'_bin'] = train_df[col].apply(lambda x: 1 if np.cbrt(x)>0 else 0)\n","    test_df[col+'_bin'] = test_df[col].apply(lambda x: 1 if np.cbrt(x)>0 else 0)\n","\n","print(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")\n","train_df.head()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 97/97 [02:30<00:00,  1.55s/it]"]},{"output_type":"stream","name":"stdout","text":["train_df: (600000, 194) \n","test_df: (540000, 194)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>f0</th>\n","      <th>f1</th>\n","      <th>f3</th>\n","      <th>f4</th>\n","      <th>f5</th>\n","      <th>f6</th>\n","      <th>f7</th>\n","      <th>f8</th>\n","      <th>f9</th>\n","      <th>f10</th>\n","      <th>f11</th>\n","      <th>f12</th>\n","      <th>f13</th>\n","      <th>f14</th>\n","      <th>f15</th>\n","      <th>f16</th>\n","      <th>f17</th>\n","      <th>f18</th>\n","      <th>f19</th>\n","      <th>f20</th>\n","      <th>f21</th>\n","      <th>f22</th>\n","      <th>f23</th>\n","      <th>f24</th>\n","      <th>f25</th>\n","      <th>f26</th>\n","      <th>f27</th>\n","      <th>f28</th>\n","      <th>f29</th>\n","      <th>f30</th>\n","      <th>f31</th>\n","      <th>f32</th>\n","      <th>f33</th>\n","      <th>f34</th>\n","      <th>f36</th>\n","      <th>f37</th>\n","      <th>f38</th>\n","      <th>f39</th>\n","      <th>f40</th>\n","      <th>f41</th>\n","      <th>...</th>\n","      <th>f60_bin</th>\n","      <th>f61_bin</th>\n","      <th>f62_bin</th>\n","      <th>f63_bin</th>\n","      <th>f64_bin</th>\n","      <th>f65_bin</th>\n","      <th>f66_bin</th>\n","      <th>f67_bin</th>\n","      <th>f68_bin</th>\n","      <th>f69_bin</th>\n","      <th>f70_bin</th>\n","      <th>f71_bin</th>\n","      <th>f72_bin</th>\n","      <th>f73_bin</th>\n","      <th>f74_bin</th>\n","      <th>f75_bin</th>\n","      <th>f76_bin</th>\n","      <th>f77_bin</th>\n","      <th>f78_bin</th>\n","      <th>f79_bin</th>\n","      <th>f80_bin</th>\n","      <th>f81_bin</th>\n","      <th>f82_bin</th>\n","      <th>f83_bin</th>\n","      <th>f84_bin</th>\n","      <th>f85_bin</th>\n","      <th>f86_bin</th>\n","      <th>f87_bin</th>\n","      <th>f88_bin</th>\n","      <th>f89_bin</th>\n","      <th>f90_bin</th>\n","      <th>f91_bin</th>\n","      <th>f92_bin</th>\n","      <th>f93_bin</th>\n","      <th>f94_bin</th>\n","      <th>f95_bin</th>\n","      <th>f96_bin</th>\n","      <th>f97_bin</th>\n","      <th>f98_bin</th>\n","      <th>f99_bin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.106643</td>\n","      <td>3.59437</td>\n","      <td>3.18428</td>\n","      <td>0.081971</td>\n","      <td>1.18859</td>\n","      <td>3.73238</td>\n","      <td>2.266270</td>\n","      <td>2.09959</td>\n","      <td>0.012330</td>\n","      <td>1.607190</td>\n","      <td>-0.318058</td>\n","      <td>0.560137</td>\n","      <td>2.806880</td>\n","      <td>1.35114</td>\n","      <td>2.535930</td>\n","      <td>0.197527</td>\n","      <td>0.676494</td>\n","      <td>1.98979</td>\n","      <td>-3.842450</td>\n","      <td>0.037380</td>\n","      <td>0.230322</td>\n","      <td>3.33055</td>\n","      <td>0.009397</td>\n","      <td>0.144738</td>\n","      <td>3.05131</td>\n","      <td>1.30362</td>\n","      <td>0.033225</td>\n","      <td>-0.018284</td>\n","      <td>2.748210</td>\n","      <td>-0.009294</td>\n","      <td>-0.036271</td>\n","      <td>-0.049871</td>\n","      <td>0.019484</td>\n","      <td>3.898460</td>\n","      <td>1.138020</td>\n","      <td>3.366880</td>\n","      <td>4.94446</td>\n","      <td>-0.105772</td>\n","      <td>2.11345</td>\n","      <td>3.452230</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.125021</td>\n","      <td>1.67336</td>\n","      <td>3.37825</td>\n","      <td>0.099400</td>\n","      <td>5.09366</td>\n","      <td>1.27562</td>\n","      <td>-0.471318</td>\n","      <td>4.54594</td>\n","      <td>0.037706</td>\n","      <td>0.331749</td>\n","      <td>0.325091</td>\n","      <td>0.062040</td>\n","      <td>2.262150</td>\n","      <td>4.33943</td>\n","      <td>-0.224999</td>\n","      <td>0.233586</td>\n","      <td>3.381280</td>\n","      <td>1.90299</td>\n","      <td>0.067874</td>\n","      <td>-0.051268</td>\n","      <td>0.006135</td>\n","      <td>2.60444</td>\n","      <td>0.103441</td>\n","      <td>0.067638</td>\n","      <td>4.75362</td>\n","      <td>1.85552</td>\n","      <td>-0.181834</td>\n","      <td>0.008359</td>\n","      <td>3.166340</td>\n","      <td>0.011850</td>\n","      <td>0.022292</td>\n","      <td>0.069320</td>\n","      <td>0.117109</td>\n","      <td>0.315276</td>\n","      <td>1.672270</td>\n","      <td>-0.409067</td>\n","      <td>4.95475</td>\n","      <td>0.092358</td>\n","      <td>2.60318</td>\n","      <td>1.954690</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.036330</td>\n","      <td>1.49747</td>\n","      <td>2.19435</td>\n","      <td>0.026914</td>\n","      <td>3.12694</td>\n","      <td>5.05687</td>\n","      <td>3.849460</td>\n","      <td>1.80187</td>\n","      <td>0.056995</td>\n","      <td>0.328684</td>\n","      <td>2.968810</td>\n","      <td>0.105244</td>\n","      <td>2.069490</td>\n","      <td>5.30986</td>\n","      <td>1.354790</td>\n","      <td>-0.262018</td>\n","      <td>1.379080</td>\n","      <td>1.48091</td>\n","      <td>0.020542</td>\n","      <td>-0.008806</td>\n","      <td>0.109348</td>\n","      <td>1.68365</td>\n","      <td>0.038180</td>\n","      <td>0.123716</td>\n","      <td>1.11248</td>\n","      <td>3.57166</td>\n","      <td>0.120601</td>\n","      <td>0.082069</td>\n","      <td>2.233520</td>\n","      <td>0.002270</td>\n","      <td>0.045182</td>\n","      <td>0.014405</td>\n","      <td>0.011599</td>\n","      <td>-0.502849</td>\n","      <td>1.417500</td>\n","      <td>1.071350</td>\n","      <td>3.22296</td>\n","      <td>2.122030</td>\n","      <td>3.08216</td>\n","      <td>0.637555</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.014077</td>\n","      <td>0.24600</td>\n","      <td>1.89064</td>\n","      <td>0.006948</td>\n","      <td>1.53112</td>\n","      <td>2.69800</td>\n","      <td>4.517330</td>\n","      <td>4.50332</td>\n","      <td>0.123494</td>\n","      <td>1.002680</td>\n","      <td>4.869600</td>\n","      <td>0.058411</td>\n","      <td>2.497850</td>\n","      <td>1.23843</td>\n","      <td>2.348360</td>\n","      <td>0.175475</td>\n","      <td>1.608890</td>\n","      <td>2.02881</td>\n","      <td>0.042086</td>\n","      <td>0.005141</td>\n","      <td>0.076506</td>\n","      <td>1.65122</td>\n","      <td>0.111813</td>\n","      <td>0.121641</td>\n","      <td>0.58912</td>\n","      <td>4.23692</td>\n","      <td>-0.032843</td>\n","      <td>0.058168</td>\n","      <td>0.712927</td>\n","      <td>0.097465</td>\n","      <td>0.072744</td>\n","      <td>0.000324</td>\n","      <td>0.063362</td>\n","      <td>4.063820</td>\n","      <td>0.576572</td>\n","      <td>2.026210</td>\n","      <td>2.96843</td>\n","      <td>1.085670</td>\n","      <td>1.71088</td>\n","      <td>1.371820</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.003259</td>\n","      <td>3.71542</td>\n","      <td>2.14772</td>\n","      <td>0.018284</td>\n","      <td>2.09859</td>\n","      <td>4.15492</td>\n","      <td>-0.038236</td>\n","      <td>3.37145</td>\n","      <td>0.034166</td>\n","      <td>0.711483</td>\n","      <td>0.769988</td>\n","      <td>0.057555</td>\n","      <td>0.957257</td>\n","      <td>3.71145</td>\n","      <td>5.464350</td>\n","      <td>0.287104</td>\n","      <td>2.616950</td>\n","      <td>1.38403</td>\n","      <td>0.074883</td>\n","      <td>-0.010543</td>\n","      <td>0.109121</td>\n","      <td>2.27602</td>\n","      <td>0.008023</td>\n","      <td>0.045236</td>\n","      <td>4.35954</td>\n","      <td>5.07562</td>\n","      <td>-0.009376</td>\n","      <td>0.528966</td>\n","      <td>4.053350</td>\n","      <td>0.020000</td>\n","      <td>0.106828</td>\n","      <td>0.051307</td>\n","      <td>0.045939</td>\n","      <td>3.402460</td>\n","      <td>1.635960</td>\n","      <td>0.047029</td>\n","      <td>4.01771</td>\n","      <td>0.155748</td>\n","      <td>5.28998</td>\n","      <td>4.118920</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 194 columns</p>\n","</div>"],"text/plain":["         f0       f1       f3        f4  ...  f96_bin  f97_bin  f98_bin  f99_bin\n","0  0.106643  3.59437  3.18428  0.081971  ...        1        1        1        1\n","1  0.125021  1.67336  3.37825  0.099400  ...        0        1        0        1\n","2  0.036330  1.49747  2.19435  0.026914  ...        0        1        1        1\n","3 -0.014077  0.24600  1.89064  0.006948  ...        1        1        1        1\n","4 -0.003259  3.71542  2.14772  0.018284  ...        1        1        0        1\n","\n","[5 rows x 194 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"ufpNaBHZSrHf","executionInfo":{"status":"ok","timestamp":1637209551735,"user_tz":-540,"elapsed":268,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}}},"source":["train_df = pd.concat([train_df, train['target']],axis = 1)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujxLYRgjAax3","executionInfo":{"status":"ok","timestamp":1637209553747,"user_tz":-540,"elapsed":254,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"f602d846-9121-4613-a4e7-eb7c8908358d"},"source":["features = test_df.columns.tolist()\n","print(f\"Num features: {len(features)}\")"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Num features: 194\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ik2qktHAa0K","executionInfo":{"status":"ok","timestamp":1637209556118,"user_tz":-540,"elapsed":1205,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"eee403f8-ce23-4b87-f543-775a3dd0736a"},"source":["train_df[features] = train_df[features].astype('float32')\n","test_df[features] = test_df[features].astype('float32')\n","print(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["train_df: (600000, 195) \n","test_df: (540000, 194)\n"]}]},{"cell_type":"markdown","metadata":{"id":"qe-mPZeTfuzt"},"source":["# Model1-DNN"]},{"cell_type":"code","metadata":{"id":"SUd0qwmbAa1_","executionInfo":{"status":"ok","timestamp":1637209472481,"user_tz":-540,"elapsed":2237,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}}},"source":["import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam, Adamax\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from tensorflow.keras.layers import Concatenate\n","from tensorflow.keras.layers import Input, BatchNormalization\n","from tensorflow.keras.layers import Dense, Dropout, Multiply\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"BuXyZycgAa4D","executionInfo":{"status":"ok","timestamp":1637209473251,"user_tz":-540,"elapsed":3,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}}},"source":["def plot_confusion_matrix(cm, classes):\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","    plt.title('Confusion matrix', fontweight='bold', pad=15)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=0)\n","    plt.yticks(tick_marks, classes)\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], 'd'),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label', fontweight='bold')\n","    plt.xlabel('Predicted label', fontweight='bold')\n","    plt.tight_layout()"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"58Lgo8jrAa7k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637209489424,"user_tz":-540,"elapsed":12316,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"ad0b3d0f-59f7-4589-cd45-8513491486b6"},"source":["def dnn_model1():\n","    \n","    x_input = Input(shape=(len(features),))\n","    \n","    x1 = Dense(units=384, activation='swish')(x_input)\n","    x1 = BatchNormalization()(x1)\n","    x2 = Dropout(rate=0.45)(x1)\n","    \n","    x2 = Dense(units=192, activation='swish')(x2)\n","    x2 = BatchNormalization()(x2)\n","    x3 = Dropout(rate=0.35)(x2)\n","    \n","    x3 = Dense(units=96, activation='swish')(x3)\n","    x3 = BatchNormalization()(x3)\n","    x3 = Dropout(rate=0.25)(x3)\n","    \n","    x4 = Dense(units=192, activation='swish')(x3)\n","    x4 = BatchNormalization()(x4)\n","    x4 = Multiply()([x2, x4])\n","    x4 = Dropout(rate=0.35)(x4)\n","    \n","    x5 = Dense(units=384, activation='swish')(x4)\n","    x5 = BatchNormalization()(x5)\n","    x5 = Multiply()([x1, x5])\n","    x5 = Dropout(rate=0.45)(x5)\n","    \n","    x = Concatenate()([x3, x5])\n","    x = Dense(units=128, activation='swish')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(rate=0.25)(x)\n","    \n","    x_output = Dense(units=1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=x_input, outputs=x_output, \n","                  name='DNN_Model')\n","    return model\n","\n","model1 = dnn_model1()\n","model1.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"DNN_Model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 194)]        0           []                               \n","                                                                                                  \n"," dense (Dense)                  (None, 384)          74880       ['input_1[0][0]']                \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 384)         1536        ['dense[0][0]']                  \n"," alization)                                                                                       \n","                                                                                                  \n"," dropout (Dropout)              (None, 384)          0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," dense_1 (Dense)                (None, 192)          73920       ['dropout[0][0]']                \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 192)         768         ['dense_1[0][0]']                \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 192)          0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," dense_2 (Dense)                (None, 96)           18528       ['dropout_1[0][0]']              \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 96)          384         ['dense_2[0][0]']                \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 96)           0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," dense_3 (Dense)                (None, 192)          18624       ['dropout_2[0][0]']              \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 192)         768         ['dense_3[0][0]']                \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multiply (Multiply)            (None, 192)          0           ['batch_normalization_1[0][0]',  \n","                                                                  'batch_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 192)          0           ['multiply[0][0]']               \n","                                                                                                  \n"," dense_4 (Dense)                (None, 384)          74112       ['dropout_3[0][0]']              \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 384)         1536        ['dense_4[0][0]']                \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multiply_1 (Multiply)          (None, 384)          0           ['batch_normalization[0][0]',    \n","                                                                  'batch_normalization_4[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 384)          0           ['multiply_1[0][0]']             \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 480)          0           ['dropout_2[0][0]',              \n","                                                                  'dropout_4[0][0]']              \n","                                                                                                  \n"," dense_5 (Dense)                (None, 128)          61568       ['concatenate[0][0]']            \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 128)         512         ['dense_5[0][0]']                \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 128)          0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," dense_6 (Dense)                (None, 1)            129         ['dropout_5[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 327,265\n","Trainable params: 324,513\n","Non-trainable params: 2,752\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZZs5BVBfj70","executionInfo":{"status":"ok","timestamp":1637213821648,"user_tz":-540,"elapsed":272,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"34403e6a-37fe-48dc-910f-47e3ae97ce0e"},"source":["def dnn_model2():\n","    \n","    x_input = Input(shape=(len(features),))\n","    \n","    x1 = Dense(units=196, activation='swish')(x_input)\n","    x1 = BatchNormalization()(x1)\n","    x2 = Dropout(rate=0.45)(x1)\n","    \n","    x2 = Dense(units=96, activation='swish')(x2)\n","    x2 = BatchNormalization()(x2)\n","    x3 = Dropout(rate=0.35)(x2)\n","    \n","    x3 = Dense(units=48, activation='swish')(x3)\n","    x3 = BatchNormalization()(x3)\n","    x3 = Dropout(rate=0.25)(x3)\n","    \n","    x4 = Dense(units=96, activation='swish')(x3)\n","    x4 = BatchNormalization()(x4)\n","    x4 = Multiply()([x2, x4])\n","    x4 = Dropout(rate=0.35)(x4)\n","    \n","    x5 = Dense(units=196, activation='swish')(x4)\n","    x5 = BatchNormalization()(x5)\n","    x5 = Multiply()([x1, x5])\n","    x5 = Dropout(rate=0.45)(x5)\n","    \n","    x = Concatenate()([x3, x5])\n","    x = Dense(units=64, activation='swish')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(rate=0.25)(x)\n","    \n","    x_output = Dense(units=1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=x_input, outputs=x_output, \n","                  name='DNN_Model')\n","    return model\n","\n","model2 = dnn_model2()\n","model2.summary()"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"DNN_Model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_15 (InputLayer)          [(None, 194)]        0           []                               \n","                                                                                                  \n"," dense_96 (Dense)               (None, 196)          38220       ['input_15[0][0]']               \n","                                                                                                  \n"," batch_normalization_83 (BatchN  (None, 196)         784         ['dense_96[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dropout_82 (Dropout)           (None, 196)          0           ['batch_normalization_83[0][0]'] \n","                                                                                                  \n"," dense_97 (Dense)               (None, 96)           18912       ['dropout_82[0][0]']             \n","                                                                                                  \n"," batch_normalization_84 (BatchN  (None, 96)          384         ['dense_97[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dropout_83 (Dropout)           (None, 96)           0           ['batch_normalization_84[0][0]'] \n","                                                                                                  \n"," dense_98 (Dense)               (None, 48)           4656        ['dropout_83[0][0]']             \n","                                                                                                  \n"," batch_normalization_85 (BatchN  (None, 48)          192         ['dense_98[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dropout_84 (Dropout)           (None, 48)           0           ['batch_normalization_85[0][0]'] \n","                                                                                                  \n"," dense_99 (Dense)               (None, 96)           4704        ['dropout_84[0][0]']             \n","                                                                                                  \n"," batch_normalization_86 (BatchN  (None, 96)          384         ['dense_99[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multiply_28 (Multiply)         (None, 96)           0           ['batch_normalization_84[0][0]', \n","                                                                  'batch_normalization_86[0][0]'] \n","                                                                                                  \n"," dropout_85 (Dropout)           (None, 96)           0           ['multiply_28[0][0]']            \n","                                                                                                  \n"," dense_100 (Dense)              (None, 196)          19012       ['dropout_85[0][0]']             \n","                                                                                                  \n"," batch_normalization_87 (BatchN  (None, 196)         784         ['dense_100[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multiply_29 (Multiply)         (None, 196)          0           ['batch_normalization_83[0][0]', \n","                                                                  'batch_normalization_87[0][0]'] \n","                                                                                                  \n"," dropout_86 (Dropout)           (None, 196)          0           ['multiply_29[0][0]']            \n","                                                                                                  \n"," concatenate_13 (Concatenate)   (None, 244)          0           ['dropout_84[0][0]',             \n","                                                                  'dropout_86[0][0]']             \n","                                                                                                  \n"," dense_101 (Dense)              (None, 64)           15680       ['concatenate_13[0][0]']         \n","                                                                                                  \n"," batch_normalization_88 (BatchN  (None, 64)          256         ['dense_101[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dropout_87 (Dropout)           (None, 64)           0           ['batch_normalization_88[0][0]'] \n","                                                                                                  \n"," dense_102 (Dense)              (None, 1)            65          ['dropout_87[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 104,033\n","Trainable params: 102,641\n","Non-trainable params: 1,392\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVNkI2fzfqih","executionInfo":{"status":"ok","timestamp":1637213869808,"user_tz":-540,"elapsed":287,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"e04b7c0b-c729-48eb-c473-889acfdac1b2"},"source":["def dnn_model3():\n","    \n","    x_input = Input(shape=(len(features),))\n","    \n","    x1 = Dense(units=98, activation='swish')(x_input)\n","    x1 = BatchNormalization()(x1)\n","    x2 = Dropout(rate=0.45)(x1)\n","    \n","    x2 = Dense(units=48, activation='swish')(x2)\n","    x2 = BatchNormalization()(x2)\n","    x3 = Dropout(rate=0.35)(x2)\n","    \n","    x3 = Dense(units=24, activation='swish')(x3)\n","    x3 = BatchNormalization()(x3)\n","    x3 = Dropout(rate=0.25)(x3)\n","    \n","    x4 = Dense(units=48, activation='swish')(x3)\n","    x4 = BatchNormalization()(x4)\n","    x4 = Multiply()([x2, x4])\n","    x4 = Dropout(rate=0.35)(x4)\n","    \n","    x5 = Dense(units=98, activation='swish')(x4)\n","    x5 = BatchNormalization()(x5)\n","    x5 = Multiply()([x1, x5])\n","    x5 = Dropout(rate=0.45)(x5)\n","    \n","    x = Concatenate()([x3, x5])\n","    x = Dense(units=32, activation='swish')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(rate=0.25)(x)\n","    \n","    x_output = Dense(units=1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=x_input, outputs=x_output, \n","                  name='DNN_Model')\n","    return model\n","\n","model3 = dnn_model3()\n","model3.summary()"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"DNN_Model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_18 (InputLayer)          [(None, 194)]        0           []                               \n","                                                                                                  \n"," dense_115 (Dense)              (None, 98)           19110       ['input_18[0][0]']               \n","                                                                                                  \n"," batch_normalization_100 (Batch  (None, 98)          392         ['dense_115[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," dropout_98 (Dropout)           (None, 98)           0           ['batch_normalization_100[0][0]']\n","                                                                                                  \n"," dense_116 (Dense)              (None, 48)           4752        ['dropout_98[0][0]']             \n","                                                                                                  \n"," batch_normalization_101 (Batch  (None, 48)          192         ['dense_116[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," dropout_99 (Dropout)           (None, 48)           0           ['batch_normalization_101[0][0]']\n","                                                                                                  \n"," dense_117 (Dense)              (None, 24)           1176        ['dropout_99[0][0]']             \n","                                                                                                  \n"," batch_normalization_102 (Batch  (None, 24)          96          ['dense_117[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," dropout_100 (Dropout)          (None, 24)           0           ['batch_normalization_102[0][0]']\n","                                                                                                  \n"," dense_118 (Dense)              (None, 48)           1200        ['dropout_100[0][0]']            \n","                                                                                                  \n"," batch_normalization_103 (Batch  (None, 48)          192         ['dense_118[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," multiply_34 (Multiply)         (None, 48)           0           ['batch_normalization_101[0][0]',\n","                                                                  'batch_normalization_103[0][0]']\n","                                                                                                  \n"," dropout_101 (Dropout)          (None, 48)           0           ['multiply_34[0][0]']            \n","                                                                                                  \n"," dense_119 (Dense)              (None, 98)           4802        ['dropout_101[0][0]']            \n","                                                                                                  \n"," batch_normalization_104 (Batch  (None, 98)          392         ['dense_119[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," multiply_35 (Multiply)         (None, 98)           0           ['batch_normalization_100[0][0]',\n","                                                                  'batch_normalization_104[0][0]']\n","                                                                                                  \n"," dropout_102 (Dropout)          (None, 98)           0           ['multiply_35[0][0]']            \n","                                                                                                  \n"," concatenate_15 (Concatenate)   (None, 122)          0           ['dropout_100[0][0]',            \n","                                                                  'dropout_102[0][0]']            \n","                                                                                                  \n"," dense_120 (Dense)              (None, 32)           3936        ['concatenate_15[0][0]']         \n","                                                                                                  \n"," batch_normalization_105 (Batch  (None, 32)          128         ['dense_120[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," dropout_103 (Dropout)          (None, 32)           0           ['batch_normalization_105[0][0]']\n","                                                                                                  \n"," dense_121 (Dense)              (None, 1)            33          ['dropout_103[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 36,401\n","Trainable params: 35,705\n","Non-trainable params: 696\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSnPy18Z5_fN","executionInfo":{"status":"ok","timestamp":1637221483410,"user_tz":-540,"elapsed":300,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"fe8a4581-cb74-4126-a9d9-edf9f31aeeb7"},"source":["def dnn_model4():\n","    \n","    x_input = Input(shape=(len(features),))\n","    \n","    x1 = Dense(units=49, activation='swish')(x_input)\n","    x1 = BatchNormalization()(x1)\n","    x2 = Dropout(rate=0.45)(x1)\n","    \n","    x2 = Dense(units=24, activation='swish')(x2)\n","    x2 = BatchNormalization()(x2)\n","    x3 = Dropout(rate=0.35)(x2)\n","    \n","    x3 = Dense(units=12, activation='swish')(x3)\n","    x3 = BatchNormalization()(x3)\n","    x3 = Dropout(rate=0.25)(x3)\n","    \n","    x4 = Dense(units=24, activation='swish')(x3)\n","    x4 = BatchNormalization()(x4)\n","    x4 = Multiply()([x2, x4])\n","    x4 = Dropout(rate=0.35)(x4)\n","    \n","    x5 = Dense(units=49, activation='swish')(x4)\n","    x5 = BatchNormalization()(x5)\n","    x5 = Multiply()([x1, x5])\n","    x5 = Dropout(rate=0.45)(x5)\n","    \n","    x = Concatenate()([x3, x5])\n","    x = Dense(units=16, activation='swish')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(rate=0.25)(x)\n","    \n","    x_output = Dense(units=1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=x_input, outputs=x_output, \n","                  name='DNN_Model')\n","    return model\n","\n","model4 = dnn_model4()\n","model4.summary()"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"DNN_Model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_39 (InputLayer)          [(None, 194)]        0           []                               \n","                                                                                                  \n"," dense_262 (Dense)              (None, 49)           9555        ['input_39[0][0]']               \n","                                                                                                  \n"," batch_normalization_226 (Batch  (None, 49)          196         ['dense_262[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," dropout_224 (Dropout)          (None, 49)           0           ['batch_normalization_226[0][0]']\n","                                                                                                  \n"," dense_263 (Dense)              (None, 24)           1200        ['dropout_224[0][0]']            \n","                                                                                                  \n"," batch_normalization_227 (Batch  (None, 24)          96          ['dense_263[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," dropout_225 (Dropout)          (None, 24)           0           ['batch_normalization_227[0][0]']\n","                                                                                                  \n"," dense_264 (Dense)              (None, 12)           300         ['dropout_225[0][0]']            \n","                                                                                                  \n"," batch_normalization_228 (Batch  (None, 12)          48          ['dense_264[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," dropout_226 (Dropout)          (None, 12)           0           ['batch_normalization_228[0][0]']\n","                                                                                                  \n"," dense_265 (Dense)              (None, 24)           312         ['dropout_226[0][0]']            \n","                                                                                                  \n"," batch_normalization_229 (Batch  (None, 24)          96          ['dense_265[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," multiply_76 (Multiply)         (None, 24)           0           ['batch_normalization_227[0][0]',\n","                                                                  'batch_normalization_229[0][0]']\n","                                                                                                  \n"," dropout_227 (Dropout)          (None, 24)           0           ['multiply_76[0][0]']            \n","                                                                                                  \n"," dense_266 (Dense)              (None, 49)           1225        ['dropout_227[0][0]']            \n","                                                                                                  \n"," batch_normalization_230 (Batch  (None, 49)          196         ['dense_266[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," multiply_77 (Multiply)         (None, 49)           0           ['batch_normalization_226[0][0]',\n","                                                                  'batch_normalization_230[0][0]']\n","                                                                                                  \n"," dropout_228 (Dropout)          (None, 49)           0           ['multiply_77[0][0]']            \n","                                                                                                  \n"," concatenate_36 (Concatenate)   (None, 61)           0           ['dropout_226[0][0]',            \n","                                                                  'dropout_228[0][0]']            \n","                                                                                                  \n"," dense_267 (Dense)              (None, 16)           992         ['concatenate_36[0][0]']         \n","                                                                                                  \n"," batch_normalization_231 (Batch  (None, 16)          64          ['dense_267[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," dropout_229 (Dropout)          (None, 16)           0           ['batch_normalization_231[0][0]']\n","                                                                                                  \n"," dense_268 (Dense)              (None, 1)            17          ['dropout_229[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 14,297\n","Trainable params: 13,949\n","Non-trainable params: 348\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"AwT8Rw3-f2KK"},"source":["**dnn_Model1**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KjGclz27Aa9i","executionInfo":{"status":"ok","timestamp":1637213222932,"user_tz":-540,"elapsed":3659937,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"ac3ce164-895e-4f4f-c32f-bff0301d6079"},"source":["### dnn_model1\n","\n","FOLD = 5\n","VERBOSE = 0\n","SEEDS = [2021, 2025]\n","BATCH_SIZE = 512\n","\n","counter = 0\n","oof_score = 0\n","y_pred_final_dnn = np.zeros((test_df.shape[0], 1))\n","y_pred_meta_dnn = np.zeros((train_df.shape[0], 1))\n","\n","\n","for sidx, seed in enumerate(SEEDS):\n","    seed_score = 0\n","    \n","    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n","\n","    for idx, (train, val) in enumerate(kfold.split(train_df[features], train_df['target'])):\n","        counter += 1\n","\n","        train_x, train_y = train_df[features].iloc[train], train_df['target'].iloc[train]\n","        val_x, val_y = train_df[features].iloc[val], train_df['target'].iloc[val]\n","\n","        model1 = dnn_model1()\n","        model1.compile(optimizer=Adam(learning_rate=1e-2), \n","                      loss=\"binary_crossentropy\", \n","                      metrics=['AUC'])\n","\n","        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n","                               patience=4, verbose=VERBOSE)\n","        \n","        chk_point = ModelCheckpoint(f'./Keras_DNN_Model_{counter}C.h5', \n","                                    monitor='val_loss', verbose=VERBOSE, \n","                                    save_best_only=True, mode='min')\n","\n","        es = EarlyStopping(monitor=\"val_loss\", patience=15, \n","                           verbose=VERBOSE, mode=\"min\", \n","                           restore_best_weights=True)\n","        \n","        model1.fit(train_x, train_y, \n","                  validation_data=(val_x, val_y), \n","                  epochs=300,\n","                  verbose=VERBOSE,\n","                  batch_size=BATCH_SIZE, \n","                  callbacks=[lr, chk_point, es])\n","        \n","        model1 = load_model(f'./Keras_DNN_Model_{counter}C.h5')\n","        \n","        y_pred = model1.predict(val_x, batch_size=BATCH_SIZE)\n","        y_pred_meta_dnn[val] += y_pred\n","        y_pred_final_dnn += model1.predict(test_df, batch_size=BATCH_SIZE)\n","        \n","        score = roc_auc_score(val_y, y_pred)\n","        oof_score += score\n","        seed_score += score\n","        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n","        \n","        del model1, y_pred\n","        del train_x, train_y\n","        del val_x, val_y\n","        gc.collect()\n","    \n","    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n","\n","\n","y_pred_meta_dnn = y_pred_meta_dnn / float(len(SEEDS))\n","y_pred_final_dnn = y_pred_final_dnn / float(counter)\n","oof_score /= float(counter)\n","print(\"Aggregate OOF Score: {}\".format(oof_score))"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-0 | OOF Score: 0.7527734954240652\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-1 | OOF Score: 0.7566354546198236\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-2 | OOF Score: 0.7571359217485271\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-3 | OOF Score: 0.7559652640941256\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-4 | OOF Score: 0.7568164389723815\n","\n","\n","Seed: 2021 | Aggregate OOF Score: 0.7558653149717847\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-0 | OOF Score: 0.7532582805660633\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-1 | OOF Score: 0.7561136274622815\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-2 | OOF Score: 0.7574400717789872\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-3 | OOF Score: 0.7544944849076469\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-4 | OOF Score: 0.7572055679575798\n","\n","\n","Seed: 2025 | Aggregate OOF Score: 0.7557024065345116\n","\n","\n","Aggregate OOF Score: 0.7557838607531482\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7vBriXnArby","executionInfo":{"status":"ok","timestamp":1637213485892,"user_tz":-540,"elapsed":1564,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"6b650f29-16bb-4833-a65e-2bec01ca1877"},"source":["y_pred_meta = np.mean(y_pred_meta_dnn, axis=1)\n","y_pred = (y_pred_meta>0.5).astype(int)\n","print(classification_report(train_df['target'], y_pred))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.74      0.73      0.74    296394\n","           1       0.74      0.75      0.75    303606\n","\n","    accuracy                           0.74    600000\n","   macro avg       0.74      0.74      0.74    600000\n","weighted avg       0.74      0.74      0.74    600000\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"HV6_wyqSAtRl","executionInfo":{"status":"ok","timestamp":1637213485893,"user_tz":-540,"elapsed":7,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"0214fe8b-02c5-411f-cbcc-68a11c34c5e6"},"source":["cnf_matrix = confusion_matrix(train_df['target'], y_pred, labels=[0, 1])\n","np.set_printoptions(precision=2)\n","plt.figure(figsize=(12, 5))"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{},"execution_count":22},{"output_type":"display_data","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"b8CoUhKSAvpS","executionInfo":{"status":"ok","timestamp":1637213493981,"user_tz":-540,"elapsed":2152,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"b9159941-73d5-404e-8d2b-1f2cdb7ade72"},"source":["submit_df = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/sample_submission.csv\")\n","submit_df['target'] = y_pred_final_dnn.ravel()\n","submit_df.to_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/DNN1_cbrt_Submission.csv\", index=False)\n","submit_df.head()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>600000</td>\n","      <td>0.749574</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>600001</td>\n","      <td>0.714452</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>600002</td>\n","      <td>0.765703</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>600003</td>\n","      <td>0.331450</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>600004</td>\n","      <td>0.675498</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id    target\n","0  600000  0.749574\n","1  600001  0.714452\n","2  600002  0.765703\n","3  600003  0.331450\n","4  600004  0.675498"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"5dsR5UwDfrAB"},"source":["# Model2-DNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8y3U_-zgM7g","executionInfo":{"status":"ok","timestamp":1637217125089,"user_tz":-540,"elapsed":3222892,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"3fa020a6-f020-4ced-879a-f0073bcfb30f"},"source":["FOLD = 5\n","VERBOSE = 0\n","SEEDS = [2021, 2025]\n","BATCH_SIZE = 512\n","\n","counter = 0\n","oof_score = 0\n","y_pred_final_dnn = np.zeros((test_df.shape[0], 1))\n","y_pred_meta_dnn = np.zeros((train_df.shape[0], 1))\n","\n","\n","for sidx, seed in enumerate(SEEDS):\n","    seed_score = 0\n","    \n","    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n","\n","    for idx, (train, val) in enumerate(kfold.split(train_df[features], train_df['target'])):\n","        counter += 1\n","\n","        train_x, train_y = train_df[features].iloc[train], train_df['target'].iloc[train]\n","        val_x, val_y = train_df[features].iloc[val], train_df['target'].iloc[val]\n","\n","        model2 = dnn_model2()\n","        model2.compile(optimizer=Adam(learning_rate=1e-2), \n","                      loss=\"binary_crossentropy\", \n","                      metrics=['AUC'])\n","\n","        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n","                               patience=4, verbose=VERBOSE)\n","        \n","        chk_point = ModelCheckpoint(f'./Keras_DNN_Model_{counter}C.h5', \n","                                    monitor='val_loss', verbose=VERBOSE, \n","                                    save_best_only=True, mode='min')\n","\n","        es = EarlyStopping(monitor=\"val_loss\", patience=15, \n","                           verbose=VERBOSE, mode=\"min\", \n","                           restore_best_weights=True)\n","        \n","        model2.fit(train_x, train_y, \n","                  validation_data=(val_x, val_y), \n","                  epochs=300,\n","                  verbose=VERBOSE,\n","                  batch_size=BATCH_SIZE, \n","                  callbacks=[lr, chk_point, es])\n","        \n","        model2 = load_model(f'./Keras_DNN_Model_{counter}C.h5')\n","        \n","        y_pred = model2.predict(val_x, batch_size=BATCH_SIZE)\n","        y_pred_meta_dnn[val] += y_pred\n","        y_pred_final_dnn += model2.predict(test_df, batch_size=BATCH_SIZE)\n","        \n","        score = roc_auc_score(val_y, y_pred)\n","        oof_score += score\n","        seed_score += score\n","        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n","        \n","        del model2, y_pred\n","        del train_x, train_y\n","        del val_x, val_y\n","        gc.collect()\n","    \n","    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n","\n","\n","y_pred_meta_dnn2 = y_pred_meta_dnn / float(len(SEEDS))\n","y_pred_final_dnn2 = y_pred_final_dnn / float(counter)\n","oof_score /= float(counter)\n","print(\"Aggregate OOF Score: {}\".format(oof_score))"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-0 | OOF Score: 0.7529289020314891\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-1 | OOF Score: 0.7570648995484572\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-2 | OOF Score: 0.7573637792345448\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-3 | OOF Score: 0.7557084950721631\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-4 | OOF Score: 0.7569301808589997\n","\n","\n","Seed: 2021 | Aggregate OOF Score: 0.7559992513491307\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-0 | OOF Score: 0.7533209476707662\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-1 | OOF Score: 0.7556951662030261\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-2 | OOF Score: 0.7577676518594196\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-3 | OOF Score: 0.7545757117757181\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-4 | OOF Score: 0.757107022993715\n","\n","\n","Seed: 2025 | Aggregate OOF Score: 0.755693300100529\n","\n","\n","Aggregate OOF Score: 0.7558462757248299\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ukNLc29igouB","executionInfo":{"status":"ok","timestamp":1637217127435,"user_tz":-540,"elapsed":1208,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"7d322169-1c78-45eb-93ae-49b56ed7404f"},"source":["y_pred_meta = np.mean(y_pred_meta_dnn2, axis=1)\n","y_pred = (y_pred_meta>0.5).astype(int)\n","print(classification_report(train_df['target'], y_pred))"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.74      0.73      0.74    296394\n","           1       0.74      0.75      0.75    303606\n","\n","    accuracy                           0.74    600000\n","   macro avg       0.74      0.74      0.74    600000\n","weighted avg       0.74      0.74      0.74    600000\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"D0XldD68gwIz","executionInfo":{"status":"ok","timestamp":1637217127436,"user_tz":-540,"elapsed":8,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"1f138475-d75a-4e4f-badf-37e5dab9ac3b"},"source":["cnf_matrix = confusion_matrix(train_df['target'], y_pred, labels=[0, 1])\n","np.set_printoptions(precision=2)\n","plt.figure(figsize=(12, 5))"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{},"execution_count":34},{"output_type":"display_data","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"_ZQaghKlg0Ci","executionInfo":{"status":"ok","timestamp":1637217129157,"user_tz":-540,"elapsed":1726,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"caeda5d2-1e80-4d79-bece-887ed533aa68"},"source":["submit_df2 = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/sample_submission.csv\")\n","submit_df2['target'] = y_pred_final_dnn2.ravel()\n","submit_df2.to_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/DNN_model2_Submission.csv\", index=False)\n","submit_df2.head()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>600000</td>\n","      <td>0.751021</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>600001</td>\n","      <td>0.717366</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>600002</td>\n","      <td>0.764463</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>600003</td>\n","      <td>0.332137</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>600004</td>\n","      <td>0.677350</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id    target\n","0  600000  0.751021\n","1  600001  0.717366\n","2  600002  0.764463\n","3  600003  0.332137\n","4  600004  0.677350"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"znKDRU9EpbpC"},"source":["# Model3-DNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0LCfbGEchtqf","executionInfo":{"status":"ok","timestamp":1637220983701,"user_tz":-540,"elapsed":3755504,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"6e0d902f-f13c-4fc8-e1d5-2a41ee292b0b"},"source":["FOLD = 5\n","VERBOSE = 0\n","SEEDS = [2021, 2025]\n","BATCH_SIZE = 512\n","\n","counter = 0\n","oof_score = 0\n","y_pred_final_dnn = np.zeros((test_df.shape[0], 1))\n","y_pred_meta_dnn = np.zeros((train_df.shape[0], 1))\n","\n","\n","for sidx, seed in enumerate(SEEDS):\n","    seed_score = 0\n","    \n","    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n","\n","    for idx, (train, val) in enumerate(kfold.split(train_df[features], train_df['target'])):\n","        counter += 1\n","\n","        train_x, train_y = train_df[features].iloc[train], train_df['target'].iloc[train]\n","        val_x, val_y = train_df[features].iloc[val], train_df['target'].iloc[val]\n","\n","        model3 = dnn_model3()\n","        model3.compile(optimizer=Adam(learning_rate=1e-2), \n","                      loss=\"binary_crossentropy\", \n","                      metrics=['AUC'])\n","\n","        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n","                               patience=4, verbose=VERBOSE)\n","        \n","        chk_point = ModelCheckpoint(f'./Keras_DNN_Model_{counter}C.h5', \n","                                    monitor='val_loss', verbose=VERBOSE, \n","                                    save_best_only=True, mode='min')\n","\n","        es = EarlyStopping(monitor=\"val_loss\", patience=15, \n","                           verbose=VERBOSE, mode=\"min\", \n","                           restore_best_weights=True)\n","        \n","        model3.fit(train_x, train_y, \n","                  validation_data=(val_x, val_y), \n","                  epochs=300,\n","                  verbose=VERBOSE,\n","                  batch_size=BATCH_SIZE, \n","                  callbacks=[lr, chk_point, es])\n","        \n","        model3 = load_model(f'./Keras_DNN_Model_{counter}C.h5')\n","        \n","        y_pred = model3.predict(val_x, batch_size=BATCH_SIZE)\n","        y_pred_meta_dnn[val] += y_pred\n","        y_pred_final_dnn += model3.predict(test_df, batch_size=BATCH_SIZE)\n","        \n","        score = roc_auc_score(val_y, y_pred)\n","        oof_score += score\n","        seed_score += score\n","        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n","        \n","        del model3, y_pred\n","        del train_x, train_y\n","        del val_x, val_y\n","        gc.collect()\n","    \n","    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n","\n","\n","y_pred_meta_dnn3 = y_pred_meta_dnn / float(len(SEEDS))\n","y_pred_final_dnn3 = y_pred_final_dnn / float(counter)\n","oof_score /= float(counter)\n","print(\"Aggregate OOF Score: {}\".format(oof_score))"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-0 | OOF Score: 0.7528662181188037\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-1 | OOF Score: 0.7572968756847647\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-2 | OOF Score: 0.7576959991516374\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-3 | OOF Score: 0.7556736247591024\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-4 | OOF Score: 0.7569505982599065\n","\n","\n","Seed: 2021 | Aggregate OOF Score: 0.756096663194843\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-0 | OOF Score: 0.7537682596238475\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-1 | OOF Score: 0.7559478286597773\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-2 | OOF Score: 0.7574156629765715\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-3 | OOF Score: 0.7546679919065502\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-4 | OOF Score: 0.7573783840926593\n","\n","\n","Seed: 2025 | Aggregate OOF Score: 0.7558356254518811\n","\n","\n","Aggregate OOF Score: 0.7559661443233621\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zKtZiicqhtoq","executionInfo":{"status":"ok","timestamp":1637220985912,"user_tz":-540,"elapsed":1326,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"2e5cf3ab-275f-4f99-cb04-594a5e514448"},"source":["y_pred_meta = np.mean(y_pred_meta_dnn3, axis=1)\n","y_pred = (y_pred_meta>0.5).astype(int)\n","print(classification_report(train_df['target'], y_pred))"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.74      0.73      0.74    296394\n","           1       0.74      0.75      0.75    303606\n","\n","    accuracy                           0.74    600000\n","   macro avg       0.74      0.74      0.74    600000\n","weighted avg       0.74      0.74      0.74    600000\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"7djbrZpShtmS","executionInfo":{"status":"ok","timestamp":1637220985913,"user_tz":-540,"elapsed":12,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"811216b8-cfd4-4010-f46c-fcf1d71d31df"},"source":["cnf_matrix = confusion_matrix(train_df['target'], y_pred, labels=[0, 1])\n","np.set_printoptions(precision=2)\n","plt.figure(figsize=(12, 5))"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{},"execution_count":38},{"output_type":"display_data","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"XNHj-XewhtkJ","executionInfo":{"status":"ok","timestamp":1637220987364,"user_tz":-540,"elapsed":1457,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"101c1ac4-7942-49f9-d9cf-e2d13d4947c4"},"source":["submit_df3 = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/sample_submission.csv\")\n","submit_df3['target'] = y_pred_final_dnn3.ravel()\n","submit_df3.to_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/DNN_model3_Submission.csv\", index=False)\n","submit_df3.head()"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>600000</td>\n","      <td>0.745709</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>600001</td>\n","      <td>0.721099</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>600002</td>\n","      <td>0.759180</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>600003</td>\n","      <td>0.327330</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>600004</td>\n","      <td>0.682954</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id    target\n","0  600000  0.745709\n","1  600001  0.721099\n","2  600002  0.759180\n","3  600003  0.327330\n","4  600004  0.682954"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"ufN_-ce76Q2Y"},"source":["Model4-DNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3KdsUHd6Qju","executionInfo":{"status":"ok","timestamp":1637224992705,"user_tz":-540,"elapsed":3492650,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"443977a4-8d00-411a-93d5-b03d13e1d279"},"source":["FOLD = 5\n","VERBOSE = 0\n","SEEDS = [2021, 2025]\n","BATCH_SIZE = 512\n","\n","counter = 0\n","oof_score = 0\n","y_pred_final_dnn = np.zeros((test_df.shape[0], 1))\n","y_pred_meta_dnn = np.zeros((train_df.shape[0], 1))\n","\n","\n","for sidx, seed in enumerate(SEEDS):\n","    seed_score = 0\n","    \n","    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n","\n","    for idx, (train, val) in enumerate(kfold.split(train_df[features], train_df['target'])):\n","        counter += 1\n","\n","        train_x, train_y = train_df[features].iloc[train], train_df['target'].iloc[train]\n","        val_x, val_y = train_df[features].iloc[val], train_df['target'].iloc[val]\n","\n","        model4 = dnn_model4()\n","        model4.compile(optimizer=Adam(learning_rate=1e-2), \n","                      loss=\"binary_crossentropy\", \n","                      metrics=['AUC'])\n","\n","        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n","                               patience=4, verbose=VERBOSE)\n","        \n","        chk_point = ModelCheckpoint(f'./Keras_DNN_Model_{counter}C.h5', \n","                                    monitor='val_loss', verbose=VERBOSE, \n","                                    save_best_only=True, mode='min')\n","\n","        es = EarlyStopping(monitor=\"val_loss\", patience=15, \n","                           verbose=VERBOSE, mode=\"min\", \n","                           restore_best_weights=True)\n","        \n","        model4.fit(train_x, train_y, \n","                  validation_data=(val_x, val_y), \n","                  epochs=300,\n","                  verbose=VERBOSE,\n","                  batch_size=BATCH_SIZE, \n","                  callbacks=[lr, chk_point, es])\n","        \n","        model4 = load_model(f'./Keras_DNN_Model_{counter}C.h5')\n","        \n","        y_pred = model4.predict(val_x, batch_size=BATCH_SIZE)\n","        y_pred_meta_dnn[val] += y_pred\n","        y_pred_final_dnn += model4.predict(test_df, batch_size=BATCH_SIZE)\n","        \n","        score = roc_auc_score(val_y, y_pred)\n","        oof_score += score\n","        seed_score += score\n","        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n","        \n","        del model4, y_pred\n","        del train_x, train_y\n","        del val_x, val_y\n","        gc.collect()\n","    \n","    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n","\n","\n","y_pred_meta_dnn4 = y_pred_meta_dnn / float(len(SEEDS))\n","y_pred_final_dnn4 = y_pred_final_dnn / float(counter)\n","oof_score /= float(counter)\n","print(\"Aggregate OOF Score: {}\".format(oof_score))"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-0 | OOF Score: 0.7526248195107775\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-1 | OOF Score: 0.7574569074045006\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-2 | OOF Score: 0.7572408088386965\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-3 | OOF Score: 0.7553429659007602\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-4 | OOF Score: 0.7568985223859287\n","\n","\n","Seed: 2021 | Aggregate OOF Score: 0.7559128048081327\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-0 | OOF Score: 0.7540791829934906\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-1 | OOF Score: 0.7559116102353824\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-2 | OOF Score: 0.7574831538333812\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-3 | OOF Score: 0.7544746577390427\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-4 | OOF Score: 0.7571025741550739\n","\n","\n","Seed: 2025 | Aggregate OOF Score: 0.7558102357912742\n","\n","\n","Aggregate OOF Score: 0.7558615202997034\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLh4YK5M6nGa","executionInfo":{"status":"ok","timestamp":1637224996351,"user_tz":-540,"elapsed":996,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"529d7dfb-2639-4deb-a6e1-e9341ac49405"},"source":["y_pred_meta = np.mean(y_pred_meta_dnn4, axis=1)\n","y_pred = (y_pred_meta>0.5).astype(int)\n","print(classification_report(train_df['target'], y_pred))"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.74      0.73      0.74    296394\n","           1       0.74      0.75      0.75    303606\n","\n","    accuracy                           0.74    600000\n","   macro avg       0.74      0.74      0.74    600000\n","weighted avg       0.74      0.74      0.74    600000\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"Aied6h1z6nGb","executionInfo":{"status":"ok","timestamp":1637224996352,"user_tz":-540,"elapsed":17,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"40647782-b137-457c-de8c-94b47e6c6bfa"},"source":["cnf_matrix = confusion_matrix(train_df['target'], y_pred, labels=[0, 1])\n","np.set_printoptions(precision=2)\n","plt.figure(figsize=(12, 5))"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{},"execution_count":43},{"output_type":"display_data","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"b7azgeJE6nGb","executionInfo":{"status":"ok","timestamp":1637224997847,"user_tz":-540,"elapsed":1500,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"9963007f-c7ad-4b19-ea68-34eefb83028a"},"source":["submit_df4 = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/sample_submission.csv\")\n","submit_df4['target'] = y_pred_final_dnn4.ravel()\n","submit_df4.to_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/DNN_model4_Submission.csv\", index=False)\n","submit_df4.head()"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>600000</td>\n","      <td>0.743290</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>600001</td>\n","      <td>0.724928</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>600002</td>\n","      <td>0.753394</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>600003</td>\n","      <td>0.321530</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>600004</td>\n","      <td>0.690102</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id    target\n","0  600000  0.743290\n","1  600001  0.724928\n","2  600002  0.753394\n","3  600003  0.321530\n","4  600004  0.690102"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"T-EN5V9YCr2c"},"source":["# Model5-DNN"]},{"cell_type":"code","metadata":{"id":"njpbMUrCBgno"},"source":["FOLD = 5\n","VERBOSE = 0\n","SEEDS = [2021, 2025]\n","BATCH_SIZE = 512\n","\n","counter = 0\n","oof_score = 0\n","y_pred_final_dnn = np.zeros((test_df.shape[0], 1))\n","y_pred_meta_dnn = np.zeros((train_df.shape[0], 1))\n","\n","\n","for sidx, seed in enumerate(SEEDS):\n","    seed_score = 0\n","    \n","    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n","\n","    for idx, (train, val) in enumerate(kfold.split(train_df[features], train_df['target'])):\n","        counter += 1\n","\n","        train_x, train_y = train_df[features].iloc[train], train_df['target'].iloc[train]\n","        val_x, val_y = train_df[features].iloc[val], train_df['target'].iloc[val]\n","\n","        model5 = dnn_model()\n","        model5.compile(optimizer=Adam(learning_rate=1e-2), \n","                      loss=\"binary_crossentropy\", \n","                      metrics=['AUC'])\n","\n","        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n","                               patience=4, verbose=VERBOSE)\n","        \n","        chk_point = ModelCheckpoint(f'./Keras_DNN_Model_{counter}C.h5', \n","                                    monitor='val_loss', verbose=VERBOSE, \n","                                    save_best_only=True, mode='min')\n","\n","        es = EarlyStopping(monitor=\"val_loss\", patience=15, \n","                           verbose=VERBOSE, mode=\"min\", \n","                           restore_best_weights=True)\n","        \n","        model5.fit(train_x, train_y, \n","                  validation_data=(val_x, val_y), \n","                  epochs=300,\n","                  verbose=VERBOSE,\n","                  batch_size=BATCH_SIZE, \n","                  callbacks=[lr, chk_point, es])\n","        \n","        model5 = load_model(f'./Keras_DNN_Model_{counter}C.h5')\n","        \n","        y_pred = model5.predict(val_x, batch_size=BATCH_SIZE)\n","        y_pred_meta_dnn[val] += y_pred\n","        y_pred_final_dnn += model5.predict(test_df, batch_size=BATCH_SIZE)\n","        \n","        score = roc_auc_score(val_y, y_pred)\n","        oof_score += score\n","        seed_score += score\n","        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n","        \n","        del model5, y_pred\n","        del train_x, train_y\n","        del val_x, val_y\n","        gc.collect()\n","    \n","    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n","\n","\n","y_pred_meta_dnn5 = y_pred_meta_dnn / float(len(SEEDS))\n","y_pred_final_dnn5 = y_pred_final_dnn / float(counter)\n","oof_score /= float(counter)\n","print(\"Aggregate OOF Score: {}\".format(oof_score))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J1XyVXZ5Bgpx"},"source":["y_pred_meta = np.mean(y_pred_meta_dnn5, axis=1)\n","y_pred = (y_pred_meta>0.5).astype(int)\n","print(classification_report(train_df['target'], y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMth1z4yBgr6"},"source":["cnf_matrix = confusion_matrix(train_df['target'], y_pred, labels=[0, 1])\n","np.set_printoptions(precision=2)\n","plt.figure(figsize=(12, 5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cux9O83Bgt5"},"source":["submit_df5 = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/sample_submission.csv\")\n","submit_df5['target'] = y_pred_final_dnn5.ravel()\n","submit_df5.to_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/DNN_model4_Submission.csv\", index=False)\n","submit_df5.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t1TUjP3FHYex"},"source":["# EDA-6 luca"]},{"cell_type":"markdown","metadata":{"id":"O4xgaWbJHnei"},"source":["Credits to the following beautiful notebook by Bex - https://www.kaggle.com/bextuychiev/model-explainability-with-shap-only-guide-u-need/notebook\n","\n","I have also used the following one from Luca as reference - https://www.kaggle.com/lucamassaron/feature-selection-by-boruta-shap\n","\n","Following is a good notebook on LOFO - https://www.kaggle.com/frankmollard/lofo-importance-correlations-tps-nov-21\n","\n","I am doing a simple SelectKBest (30 variables) in this data and then taking common ones from the above methods, to see what variables truly stand out.\n","\n","Will update if I add another set and once I try mutual information with my engineered variables"]},{"cell_type":"code","metadata":{"id":"lEcx7jRGtUn-"},"source":["train = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/train.csv\")\n","test = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/test.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zyqMm8ZtC_5"},"source":["train_df = train[['f1', 'f10', 'f11', 'f14', 'f15', 'f16', 'f17',\n","                     'f2', 'f20', 'f21', 'f22','f24','f25', 'f26',\n","                     'f27', 'f28', 'f3', 'f30', 'f31', 'f32', 'f33',\n","                     'f34', 'f36', 'f37', 'f4', 'f40', 'f41','f42',\n","                     'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n","                     'f5','f50', 'f51', 'f53', 'f54', 'f55', 'f57',\n","                     'f58', 'f59', 'f60', 'f61', 'f62', 'f64', 'f66',\n","                     'f67', 'f70', 'f71', 'f76','f77', 'f8', 'f80',\n","                     'f81','f82', 'f83', 'f87', 'f89', 'f9', 'f90',\n","                     'f91', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98']]\n","test_df = test[['f1', 'f10', 'f11', 'f14', 'f15', 'f16', 'f17',\n","                     'f2', 'f20', 'f21', 'f22','f24','f25', 'f26',\n","                     'f27', 'f28', 'f3', 'f30', 'f31', 'f32', 'f33',\n","                     'f34', 'f36', 'f37', 'f4', 'f40', 'f41','f42',\n","                     'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49',\n","                     'f5','f50', 'f51', 'f53', 'f54', 'f55', 'f57',\n","                     'f58', 'f59', 'f60', 'f61', 'f62', 'f64', 'f66',\n","                     'f67', 'f70', 'f71', 'f76','f77', 'f8', 'f80',\n","                     'f81','f82', 'f83', 'f87', 'f89', 'f9', 'f90',\n","                     'f91', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoSEwsGMtbny"},"source":["train_df['mean'] = train_df.mean(axis=1)\n","train_df['std'] = train_df.std(axis=1)\n","train_df['var'] = train_df.var(axis=1)\n","train_df['sum'] = train_df.sum(axis=1)\n","train_df['max'] = train_df.max(axis=1)\n","train_df['kurt'] = train_df.kurt(axis=1)\n","train_df['quantile'] = train_df.quantile(axis=1)\n","\n","\n","test_df['mean'] = test_df.mean(axis=1)\n","test_df['std'] = test_df.std(axis=1)\n","test_df['var'] = test_df.var(axis=1)\n","test_df['sum'] = test_df.sum(axis=1)\n","test_df['max'] = test_df.max(axis=1)\n","test_df['kurt'] = test_df.kurt(axis=1)\n","test_df['quantile'] = test_df.quantile(axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MyAPEKVzuJfp"},"source":["train_df = pd.concat([train_df, train['target']],axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aahrYjXuL1V","executionInfo":{"status":"ok","timestamp":1637149651084,"user_tz":-540,"elapsed":495,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"a5503edc-21da-4c31-d4b4-99530d2b9b4a"},"source":["features = test_df.columns.tolist()\n","print(f\"Num features: {len(features)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num features: 77\n"]}]},{"cell_type":"code","metadata":{"id":"JJ2Je878Hfwp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637149657613,"user_tz":-540,"elapsed":6099,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"d6ae9186-e6ef-43d3-fc2c-634b3c04083f"},"source":["train_df[features] = train_df[features].astype('float32')\n","test_df[features] = test_df[features].astype('float32')\n","print(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self[k1] = value[k2]\n"]},{"output_type":"stream","name":"stdout","text":["train_df: (600000, 78) \n","test_df: (540000, 77)\n"]}]},{"cell_type":"markdown","metadata":{"id":"SwK9z_ymHLSn"},"source":["# Model6-DNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T5YV8NFauWb4","executionInfo":{"status":"ok","timestamp":1637154104897,"user_tz":-540,"elapsed":4314812,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"7f643274-c391-4a79-a129-7bbc10d2e8a6"},"source":["FOLD = 5\n","VERBOSE = 0\n","SEEDS = [2021, 2025]\n","BATCH_SIZE = 512\n","\n","counter = 0\n","oof_score = 0\n","y_pred_final_dnn = np.zeros((test_df.shape[0], 1))\n","y_pred_meta_dnn = np.zeros((train_df.shape[0], 1))\n","\n","\n","for sidx, seed in enumerate(SEEDS):\n","    seed_score = 0\n","    \n","    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n","\n","    for idx, (train, val) in enumerate(kfold.split(train_df[features], train_df['target'])):\n","        counter += 1\n","\n","        train_x, train_y = train_df[features].iloc[train], train_df['target'].iloc[train]\n","        val_x, val_y = train_df[features].iloc[val], train_df['target'].iloc[val]\n","\n","        model6 = dnn_model()\n","        model6.compile(optimizer=Adam(learning_rate=1e-2), \n","                      loss=\"binary_crossentropy\", \n","                      metrics=['AUC'])\n","\n","        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n","                               patience=4, verbose=VERBOSE)\n","        \n","        chk_point = ModelCheckpoint(f'./Keras_DNN_Model_{counter}C.h5', \n","                                    monitor='val_loss', verbose=VERBOSE, \n","                                    save_best_only=True, mode='min')\n","\n","        es = EarlyStopping(monitor=\"val_loss\", patience=15, \n","                           verbose=VERBOSE, mode=\"min\", \n","                           restore_best_weights=True)\n","        \n","        model6.fit(train_x, train_y, \n","                  validation_data=(val_x, val_y), \n","                  epochs=300,\n","                  verbose=VERBOSE,\n","                  batch_size=BATCH_SIZE, \n","                  callbacks=[lr, chk_point, es])\n","        \n","        model6 = load_model(f'./Keras_DNN_Model_{counter}C.h5')\n","        \n","        y_pred = model6.predict(val_x, batch_size=BATCH_SIZE)\n","        y_pred_meta_dnn[val] += y_pred\n","        y_pred_final_dnn += model6.predict(test_df, batch_size=BATCH_SIZE)\n","        \n","        score = roc_auc_score(val_y, y_pred)\n","        oof_score += score\n","        seed_score += score\n","        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n","        \n","        del model6, y_pred\n","        del train_x, train_y\n","        del val_x, val_y\n","        gc.collect()\n","    \n","    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n","\n","\n","y_pred_meta_dnn6 = y_pred_meta_dnn / float(len(SEEDS))\n","y_pred_final_dnn6 = y_pred_final_dnn / float(counter)\n","oof_score /= float(counter)\n","print(\"Aggregate OOF Score: {}\".format(oof_score))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-0 | OOF Score: 0.7424148335192977\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-1 | OOF Score: 0.745809829035371\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-2 | OOF Score: 0.7467455127594718\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-3 | OOF Score: 0.7463032208368398\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-4 | OOF Score: 0.7487927579677902\n","\n","\n","Seed: 2021 | Aggregate OOF Score: 0.7460132308237541\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-0 | OOF Score: 0.7438889572165024\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-1 | OOF Score: 0.7452566569349437\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-2 | OOF Score: 0.7468646138465906\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-3 | OOF Score: 0.7456450231540226\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-4 | OOF Score: 0.7483499692681611\n","\n","\n","Seed: 2025 | Aggregate OOF Score: 0.746001044084044\n","\n","\n","Aggregate OOF Score: 0.7460071374538991\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1iZ-CvIKuWZH","executionInfo":{"status":"ok","timestamp":1637154106083,"user_tz":-540,"elapsed":1196,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"0486ce2d-bdf1-48bd-b5ae-85ed2682f784"},"source":["y_pred_meta = np.mean(y_pred_meta_dnn6, axis=1)\n","y_pred = (y_pred_meta>0.5).astype(int)\n","print(classification_report(train_df['target'], y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.73      0.72      0.72    296394\n","           1       0.73      0.74      0.73    303606\n","\n","    accuracy                           0.73    600000\n","   macro avg       0.73      0.73      0.73    600000\n","weighted avg       0.73      0.73      0.73    600000\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"X48rQO9kuWVH","executionInfo":{"status":"ok","timestamp":1637154106084,"user_tz":-540,"elapsed":9,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"ecfef8df-fb86-40a1-921b-f83b4e168cb7"},"source":["cnf_matrix = confusion_matrix(train_df['target'], y_pred, labels=[0, 1])\n","np.set_printoptions(precision=2)\n","plt.figure(figsize=(12, 5))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{},"execution_count":33},{"output_type":"display_data","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"8iR9CQajuWP2","executionInfo":{"status":"ok","timestamp":1637155106970,"user_tz":-540,"elapsed":1773,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"0ebcb3d3-e4c9-492e-a087-bcf47619a4bc"},"source":["submit_df6 = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/sample_submission.csv\")\n","submit_df6['target'] = y_pred_final_dnn6.ravel()\n","submit_df6.to_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/DNN_model6_Submission.csv\", index=False)\n","submit_df6.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>600000</td>\n","      <td>0.742414</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>600001</td>\n","      <td>0.733466</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>600002</td>\n","      <td>0.747426</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>600003</td>\n","      <td>0.606355</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>600004</td>\n","      <td>0.718100</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id    target\n","0  600000  0.742414\n","1  600001  0.733466\n","2  600002  0.747426\n","3  600003  0.606355\n","4  600004  0.718100"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"WJ4MkKZFHtQ-"},"source":["# EDA-7 my_features_f_classif "]},{"cell_type":"code","metadata":{"id":"ERaKUFOPwe8u"},"source":["train = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/train.csv\")\n","test = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/test.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Si11s5STwhbV"},"source":["train_df = train[['f3','f8','f10','f17','f21','f22','f24','f25','f26','f27','f34',\n","               'f40','f41','f43','f44','f47','f50','f54','f55','f57','f60','f66',\n","               'f71','f80','f81','f82','f91','f96','f97','f98']]\n","test_df = test[['f3','f8','f10','f17','f21','f22','f24','f25','f26','f27','f34',\n","               'f40','f41','f43','f44','f47','f50','f54','f55','f57','f60','f66',\n","               'f71','f80','f81','f82','f91','f96','f97','f98']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2mZObjguwzr7","executionInfo":{"status":"ok","timestamp":1637155133442,"user_tz":-540,"elapsed":14,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"9ec8ebd4-7a25-4c69-96b7-cba21960cee0"},"source":["features = test_df.columns.tolist()\n","len(features)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":656},"id":"zvWsunWJwzp_","executionInfo":{"status":"error","timestamp":1637155149192,"user_tz":-540,"elapsed":15761,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"5f50dc75-6ca5-4b0d-cc38-6b1243cae83e"},"source":["for col in tqdm(features):\n","    train_df[col+'_bin'] = train_df[col].apply(lambda x: 1 if np.cbrt(x)>0 else 0)\n","    test_df[col+'_bin'] = test_df[col].apply(lambda x: 1 if np.cbrt(x)>0 else 0)\n","\n","print(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"," 30%|███       | 9/30 [00:15<00:36,  1.75s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-054ede516f72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_bin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_bin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-39-054ede516f72>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_bin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_bin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ktwg_8GFwzpO"},"source":["features = test_df.columns.tolist()\n","print(f\"Num features: {len(features)}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlF2lj29wzmA"},"source":["train_df[features] = train_df[features].astype('float32')\n","test_df[features] = test_df[features].astype('float32')\n","print(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K8foUiQUHQbZ"},"source":["# Model7-DNN"]},{"cell_type":"code","metadata":{"id":"N8ehzWylxMPX"},"source":["FOLD = 5\n","VERBOSE = 0\n","SEEDS = [2021, 2025]\n","BATCH_SIZE = 512\n","\n","counter = 0\n","oof_score = 0\n","y_pred_final_dnn = np.zeros((test_df.shape[0], 1))\n","y_pred_meta_dnn = np.zeros((train_df.shape[0], 1))\n","\n","\n","for sidx, seed in enumerate(SEEDS):\n","    seed_score = 0\n","    \n","    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n","\n","    for idx, (train, val) in enumerate(kfold.split(train_df[features], train_df['target'])):\n","        counter += 1\n","\n","        train_x, train_y = train_df[features].iloc[train], train_df['target'].iloc[train]\n","        val_x, val_y = train_df[features].iloc[val], train_df['target'].iloc[val]\n","\n","        model7 = dnn_model()\n","        model7.compile(optimizer=Adam(learning_rate=1e-2), \n","                      loss=\"binary_crossentropy\", \n","                      metrics=['AUC'])\n","\n","        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n","                               patience=4, verbose=VERBOSE)\n","        \n","        chk_point = ModelCheckpoint(f'./Keras_DNN_Model_{counter}C.h5', \n","                                    monitor='val_loss', verbose=VERBOSE, \n","                                    save_best_only=True, mode='min')\n","\n","        es = EarlyStopping(monitor=\"val_loss\", patience=15, \n","                           verbose=VERBOSE, mode=\"min\", \n","                           restore_best_weights=True)\n","        \n","        model7.fit(train_x, train_y, \n","                  validation_data=(val_x, val_y), \n","                  epochs=300,\n","                  verbose=VERBOSE,\n","                  batch_size=BATCH_SIZE, \n","                  callbacks=[lr, chk_point, es])\n","        \n","        model7 = load_model(f'./Keras_DNN_Model_{counter}C.h5')\n","        \n","        y_pred = model7.predict(val_x, batch_size=BATCH_SIZE)\n","        y_pred_meta_dnn[val] += y_pred\n","        y_pred_final_dnn += model7.predict(test_df, batch_size=BATCH_SIZE)\n","        \n","        score = roc_auc_score(val_y, y_pred)\n","        oof_score += score\n","        seed_score += score\n","        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n","        \n","        del model7, y_pred\n","        del train_x, train_y\n","        del val_x, val_y\n","        gc.collect()\n","    \n","    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n","\n","\n","y_pred_meta_dnn7 = y_pred_meta_dnn / float(len(SEEDS))\n","y_pred_final_dnn7 = y_pred_final_dnn / float(counter)\n","oof_score /= float(counter)\n","print(\"Aggregate OOF Score: {}\".format(oof_score))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hl-UMwlSxMPY"},"source":["y_pred_meta = np.mean(y_pred_meta_dnn7, axis=1)\n","y_pred = (y_pred_meta>0.5).astype(int)\n","print(classification_report(train_df['target'], y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"orSYDVi7xMPY"},"source":["cnf_matrix = confusion_matrix(train_df['target'], y_pred, labels=[0, 1])\n","np.set_printoptions(precision=2)\n","plt.figure(figsize=(12, 5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mIzvHj9LxMPY"},"source":["submit_df7 = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/sample_submission.csv\")\n","submit_df7['target'] = y_pred_final_dnn5.ravel()\n","submit_df7.to_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/DNN_model7_Submission.csv\", index=False)\n","submit_df7.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pZxk3QahH6dg"},"source":["#EDA-8 lofo_features"]},{"cell_type":"code","metadata":{"id":"xj1lsGpsH9sQ"},"source":["lofo_features = set(['f34','f55','f8','f43','f91','f71','f80','f27','f50','f41','f97','f66','f57',\n","                'f22','f25','f96','f81','f82','f21','f24','f26','f54','f98','f40','f60','f3','f17',\n","                'f95','f5','f45'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PO_ib2K1HQpF"},"source":["# Model8-DNN"]},{"cell_type":"markdown","metadata":{"id":"31a119WLIKod"},"source":["#EDA-9 cor_features "]},{"cell_type":"code","metadata":{"id":"A43tjsZvIEbJ"},"source":["cor_features = set(['f34', 'f55', 'f43', 'f71', 'f80', 'f91', 'f8', 'f27', 'f97', 'f50', 'f41', 'f57',\n","                    'f25', 'f22', 'f66', 'f96', 'f81', 'f82', 'f21', 'f40', 'f24', 'f60', 'f98', 'f3',\n","                    'f54', 'f44', 'f26', 'f47', 'f17', 'f10'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qy9cI0ZlHQvb"},"source":["# Model9-DNN"]},{"cell_type":"code","metadata":{"id":"ul6F1yAZ4dE0"},"source":["train = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/train.csv\")\n","test = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/test.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CT4LlbxoGEga"},"source":["df_train = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/train.csv\")\n","df_test = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/test.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XgdvPBegGLmz"},"source":["df_train = train.drop(['target', 'id'], axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXqeiUs_GLjb"},"source":["df_test = test.drop(['id'],axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHO7QYrFD42-"},"source":["train_df = train.drop(['target', 'id'], axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRILQAHIEAgN"},"source":["test_df = test.drop(['id'],axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QEiFph4R5DaL","executionInfo":{"status":"ok","timestamp":1637157248436,"user_tz":-540,"elapsed":7,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"594dbc97-350f-4392-a5ce-2d204b368080"},"source":["features = test_df.columns.tolist()\n","len(features)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"HXflnHV6Dw3v","executionInfo":{"status":"ok","timestamp":1637157401541,"user_tz":-540,"elapsed":153110,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"b2d4fc39-c111-4e0b-9c7c-74112f2e3608"},"source":["for col in tqdm(features):\n","    train_df[col+'_bin'] = train_df[col].apply(lambda x: 1 if np.cbrt(x)>0 else 0)\n","    test_df[col+'_bin'] = test_df[col].apply(lambda x: 1 if np.cbrt(x)>0 else 0)\n","\n","print(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [02:33<00:00,  1.53s/it]"]},{"output_type":"stream","name":"stdout","text":["train_df: (600000, 200) \n","test_df: (540000, 200)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>f0</th>\n","      <th>f1</th>\n","      <th>f2</th>\n","      <th>f3</th>\n","      <th>f4</th>\n","      <th>f5</th>\n","      <th>f6</th>\n","      <th>f7</th>\n","      <th>f8</th>\n","      <th>f9</th>\n","      <th>f10</th>\n","      <th>f11</th>\n","      <th>f12</th>\n","      <th>f13</th>\n","      <th>f14</th>\n","      <th>f15</th>\n","      <th>f16</th>\n","      <th>f17</th>\n","      <th>f18</th>\n","      <th>f19</th>\n","      <th>f20</th>\n","      <th>f21</th>\n","      <th>f22</th>\n","      <th>f23</th>\n","      <th>f24</th>\n","      <th>f25</th>\n","      <th>f26</th>\n","      <th>f27</th>\n","      <th>f28</th>\n","      <th>f29</th>\n","      <th>f30</th>\n","      <th>f31</th>\n","      <th>f32</th>\n","      <th>f33</th>\n","      <th>f34</th>\n","      <th>f35</th>\n","      <th>f36</th>\n","      <th>f37</th>\n","      <th>f38</th>\n","      <th>f39</th>\n","      <th>...</th>\n","      <th>f60_bin</th>\n","      <th>f61_bin</th>\n","      <th>f62_bin</th>\n","      <th>f63_bin</th>\n","      <th>f64_bin</th>\n","      <th>f65_bin</th>\n","      <th>f66_bin</th>\n","      <th>f67_bin</th>\n","      <th>f68_bin</th>\n","      <th>f69_bin</th>\n","      <th>f70_bin</th>\n","      <th>f71_bin</th>\n","      <th>f72_bin</th>\n","      <th>f73_bin</th>\n","      <th>f74_bin</th>\n","      <th>f75_bin</th>\n","      <th>f76_bin</th>\n","      <th>f77_bin</th>\n","      <th>f78_bin</th>\n","      <th>f79_bin</th>\n","      <th>f80_bin</th>\n","      <th>f81_bin</th>\n","      <th>f82_bin</th>\n","      <th>f83_bin</th>\n","      <th>f84_bin</th>\n","      <th>f85_bin</th>\n","      <th>f86_bin</th>\n","      <th>f87_bin</th>\n","      <th>f88_bin</th>\n","      <th>f89_bin</th>\n","      <th>f90_bin</th>\n","      <th>f91_bin</th>\n","      <th>f92_bin</th>\n","      <th>f93_bin</th>\n","      <th>f94_bin</th>\n","      <th>f95_bin</th>\n","      <th>f96_bin</th>\n","      <th>f97_bin</th>\n","      <th>f98_bin</th>\n","      <th>f99_bin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.106643</td>\n","      <td>3.59437</td>\n","      <td>132.8040</td>\n","      <td>3.18428</td>\n","      <td>0.081971</td>\n","      <td>1.18859</td>\n","      <td>3.73238</td>\n","      <td>2.266270</td>\n","      <td>2.09959</td>\n","      <td>0.012330</td>\n","      <td>1.607190</td>\n","      <td>-0.318058</td>\n","      <td>0.560137</td>\n","      <td>2.806880</td>\n","      <td>1.35114</td>\n","      <td>2.535930</td>\n","      <td>0.197527</td>\n","      <td>0.676494</td>\n","      <td>1.98979</td>\n","      <td>-3.842450</td>\n","      <td>0.037380</td>\n","      <td>0.230322</td>\n","      <td>3.33055</td>\n","      <td>0.009397</td>\n","      <td>0.144738</td>\n","      <td>3.05131</td>\n","      <td>1.30362</td>\n","      <td>0.033225</td>\n","      <td>-0.018284</td>\n","      <td>2.748210</td>\n","      <td>-0.009294</td>\n","      <td>-0.036271</td>\n","      <td>-0.049871</td>\n","      <td>0.019484</td>\n","      <td>3.898460</td>\n","      <td>11.2863</td>\n","      <td>1.138020</td>\n","      <td>3.366880</td>\n","      <td>4.94446</td>\n","      <td>-0.105772</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.125021</td>\n","      <td>1.67336</td>\n","      <td>76.5336</td>\n","      <td>3.37825</td>\n","      <td>0.099400</td>\n","      <td>5.09366</td>\n","      <td>1.27562</td>\n","      <td>-0.471318</td>\n","      <td>4.54594</td>\n","      <td>0.037706</td>\n","      <td>0.331749</td>\n","      <td>0.325091</td>\n","      <td>0.062040</td>\n","      <td>2.262150</td>\n","      <td>4.33943</td>\n","      <td>-0.224999</td>\n","      <td>0.233586</td>\n","      <td>3.381280</td>\n","      <td>1.90299</td>\n","      <td>0.067874</td>\n","      <td>-0.051268</td>\n","      <td>0.006135</td>\n","      <td>2.60444</td>\n","      <td>0.103441</td>\n","      <td>0.067638</td>\n","      <td>4.75362</td>\n","      <td>1.85552</td>\n","      <td>-0.181834</td>\n","      <td>0.008359</td>\n","      <td>3.166340</td>\n","      <td>0.011850</td>\n","      <td>0.022292</td>\n","      <td>0.069320</td>\n","      <td>0.117109</td>\n","      <td>0.315276</td>\n","      <td>24.4807</td>\n","      <td>1.672270</td>\n","      <td>-0.409067</td>\n","      <td>4.95475</td>\n","      <td>0.092358</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.036330</td>\n","      <td>1.49747</td>\n","      <td>233.5460</td>\n","      <td>2.19435</td>\n","      <td>0.026914</td>\n","      <td>3.12694</td>\n","      <td>5.05687</td>\n","      <td>3.849460</td>\n","      <td>1.80187</td>\n","      <td>0.056995</td>\n","      <td>0.328684</td>\n","      <td>2.968810</td>\n","      <td>0.105244</td>\n","      <td>2.069490</td>\n","      <td>5.30986</td>\n","      <td>1.354790</td>\n","      <td>-0.262018</td>\n","      <td>1.379080</td>\n","      <td>1.48091</td>\n","      <td>0.020542</td>\n","      <td>-0.008806</td>\n","      <td>0.109348</td>\n","      <td>1.68365</td>\n","      <td>0.038180</td>\n","      <td>0.123716</td>\n","      <td>1.11248</td>\n","      <td>3.57166</td>\n","      <td>0.120601</td>\n","      <td>0.082069</td>\n","      <td>2.233520</td>\n","      <td>0.002270</td>\n","      <td>0.045182</td>\n","      <td>0.014405</td>\n","      <td>0.011599</td>\n","      <td>-0.502849</td>\n","      <td>33.7382</td>\n","      <td>1.417500</td>\n","      <td>1.071350</td>\n","      <td>3.22296</td>\n","      <td>2.122030</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.014077</td>\n","      <td>0.24600</td>\n","      <td>779.9670</td>\n","      <td>1.89064</td>\n","      <td>0.006948</td>\n","      <td>1.53112</td>\n","      <td>2.69800</td>\n","      <td>4.517330</td>\n","      <td>4.50332</td>\n","      <td>0.123494</td>\n","      <td>1.002680</td>\n","      <td>4.869600</td>\n","      <td>0.058411</td>\n","      <td>2.497850</td>\n","      <td>1.23843</td>\n","      <td>2.348360</td>\n","      <td>0.175475</td>\n","      <td>1.608890</td>\n","      <td>2.02881</td>\n","      <td>0.042086</td>\n","      <td>0.005141</td>\n","      <td>0.076506</td>\n","      <td>1.65122</td>\n","      <td>0.111813</td>\n","      <td>0.121641</td>\n","      <td>0.58912</td>\n","      <td>4.23692</td>\n","      <td>-0.032843</td>\n","      <td>0.058168</td>\n","      <td>0.712927</td>\n","      <td>0.097465</td>\n","      <td>0.072744</td>\n","      <td>0.000324</td>\n","      <td>0.063362</td>\n","      <td>4.063820</td>\n","      <td>25.3824</td>\n","      <td>0.576572</td>\n","      <td>2.026210</td>\n","      <td>2.96843</td>\n","      <td>1.085670</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.003259</td>\n","      <td>3.71542</td>\n","      <td>156.1280</td>\n","      <td>2.14772</td>\n","      <td>0.018284</td>\n","      <td>2.09859</td>\n","      <td>4.15492</td>\n","      <td>-0.038236</td>\n","      <td>3.37145</td>\n","      <td>0.034166</td>\n","      <td>0.711483</td>\n","      <td>0.769988</td>\n","      <td>0.057555</td>\n","      <td>0.957257</td>\n","      <td>3.71145</td>\n","      <td>5.464350</td>\n","      <td>0.287104</td>\n","      <td>2.616950</td>\n","      <td>1.38403</td>\n","      <td>0.074883</td>\n","      <td>-0.010543</td>\n","      <td>0.109121</td>\n","      <td>2.27602</td>\n","      <td>0.008023</td>\n","      <td>0.045236</td>\n","      <td>4.35954</td>\n","      <td>5.07562</td>\n","      <td>-0.009376</td>\n","      <td>0.528966</td>\n","      <td>4.053350</td>\n","      <td>0.020000</td>\n","      <td>0.106828</td>\n","      <td>0.051307</td>\n","      <td>0.045939</td>\n","      <td>3.402460</td>\n","      <td>15.5615</td>\n","      <td>1.635960</td>\n","      <td>0.047029</td>\n","      <td>4.01771</td>\n","      <td>0.155748</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 200 columns</p>\n","</div>"],"text/plain":["         f0       f1        f2       f3  ...  f96_bin  f97_bin  f98_bin  f99_bin\n","0  0.106643  3.59437  132.8040  3.18428  ...        1        1        1        1\n","1  0.125021  1.67336   76.5336  3.37825  ...        0        1        0        1\n","2  0.036330  1.49747  233.5460  2.19435  ...        0        1        1        1\n","3 -0.014077  0.24600  779.9670  1.89064  ...        1        1        1        1\n","4 -0.003259  3.71542  156.1280  2.14772  ...        1        1        0        1\n","\n","[5 rows x 200 columns]"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"xmM7TAdTEYvs"},"source":["df_train['mean'] = df_train.mean(axis=1)\n","df_train['std'] = df_train.std(axis=1)\n","df_train['var'] = df_train.var(axis=1)\n","df_train['sum'] = df_train.sum(axis=1)\n","df_train['max'] = df_train.max(axis=1)\n","df_train['kurt'] = df_train.kurt(axis=1)\n","df_train['quantile'] = df_train.quantile(axis=1)\n","\n","\n","df_test['mean'] = df_test.mean(axis=1)\n","df_test['std'] = df_test.std(axis=1)\n","df_test['var'] = df_test.var(axis=1)\n","df_test['sum'] = df_test.sum(axis=1)\n","df_test['max'] = df_test.max(axis=1)\n","df_test['kurt'] = df_test.kurt(axis=1)\n","df_test['quantile'] = df_test.quantile(axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3FYFkUN-E44R"},"source":["df_train = df_train[['mean','std', 'var', 'sum', 'max', 'kurt', 'quantile']]\n","df_test = df_test[['mean','std', 'var', 'sum', 'max', 'kurt', 'quantile']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"st9LmpM2HLjX"},"source":["train_df = pd.concat([train_df,df_train,train['target']],axis = 1)\n","test_df = pd.concat([test_df,df_test],axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0oaS5ofiIx0X","executionInfo":{"status":"ok","timestamp":1637157412680,"user_tz":-540,"elapsed":3,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"d853deb9-ab03-4ae7-cd76-80947a8f82be"},"source":["features = test_df.columns.tolist()\n","print(f\"Num features: {len(features)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num features: 207\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLc_K6QeI0vI","executionInfo":{"status":"ok","timestamp":1637157434467,"user_tz":-540,"elapsed":21788,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"df94df01-08f4-4a07-8033-445996a26118"},"source":["train_df[features] = train_df[features].astype('float32')\n","test_df[features] = test_df[features].astype('float32')\n","print(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_df: (600000, 208) \n","test_df: (540000, 207)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434},"id":"0ebHRr4mMAfL","executionInfo":{"status":"ok","timestamp":1637157457898,"user_tz":-540,"elapsed":696,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"67b6ee6c-b5f7-4991-9b26-7ec900ae87b7"},"source":[""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>f0</th>\n","      <th>f1</th>\n","      <th>f2</th>\n","      <th>f3</th>\n","      <th>f4</th>\n","      <th>f5</th>\n","      <th>f6</th>\n","      <th>f7</th>\n","      <th>f8</th>\n","      <th>f9</th>\n","      <th>f10</th>\n","      <th>f11</th>\n","      <th>f12</th>\n","      <th>f13</th>\n","      <th>f14</th>\n","      <th>f15</th>\n","      <th>f16</th>\n","      <th>f17</th>\n","      <th>f18</th>\n","      <th>f19</th>\n","      <th>f20</th>\n","      <th>f21</th>\n","      <th>f22</th>\n","      <th>f23</th>\n","      <th>f24</th>\n","      <th>f25</th>\n","      <th>f26</th>\n","      <th>f27</th>\n","      <th>f28</th>\n","      <th>f29</th>\n","      <th>f30</th>\n","      <th>f31</th>\n","      <th>f32</th>\n","      <th>f33</th>\n","      <th>f34</th>\n","      <th>f35</th>\n","      <th>f36</th>\n","      <th>f37</th>\n","      <th>f38</th>\n","      <th>f39</th>\n","      <th>...</th>\n","      <th>f67_bin</th>\n","      <th>f68_bin</th>\n","      <th>f69_bin</th>\n","      <th>f70_bin</th>\n","      <th>f71_bin</th>\n","      <th>f72_bin</th>\n","      <th>f73_bin</th>\n","      <th>f74_bin</th>\n","      <th>f75_bin</th>\n","      <th>f76_bin</th>\n","      <th>f77_bin</th>\n","      <th>f78_bin</th>\n","      <th>f79_bin</th>\n","      <th>f80_bin</th>\n","      <th>f81_bin</th>\n","      <th>f82_bin</th>\n","      <th>f83_bin</th>\n","      <th>f84_bin</th>\n","      <th>f85_bin</th>\n","      <th>f86_bin</th>\n","      <th>f87_bin</th>\n","      <th>f88_bin</th>\n","      <th>f89_bin</th>\n","      <th>f90_bin</th>\n","      <th>f91_bin</th>\n","      <th>f92_bin</th>\n","      <th>f93_bin</th>\n","      <th>f94_bin</th>\n","      <th>f95_bin</th>\n","      <th>f96_bin</th>\n","      <th>f97_bin</th>\n","      <th>f98_bin</th>\n","      <th>f99_bin</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>var</th>\n","      <th>sum</th>\n","      <th>max</th>\n","      <th>kurt</th>\n","      <th>quantile</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.003229</td>\n","      <td>4.838660</td>\n","      <td>585.528992</td>\n","      <td>2.282910</td>\n","      <td>0.713180</td>\n","      <td>3.907830</td>\n","      <td>0.480696</td>\n","      <td>1.482270</td>\n","      <td>4.891810</td>\n","      <td>0.056351</td>\n","      <td>4.200990</td>\n","      <td>3.151800</td>\n","      <td>0.000349</td>\n","      <td>1.851160</td>\n","      <td>2.63889</td>\n","      <td>0.746668</td>\n","      <td>-0.004756</td>\n","      <td>1.610300</td>\n","      <td>4.11482</td>\n","      <td>-0.077756</td>\n","      <td>0.129446</td>\n","      <td>0.053324</td>\n","      <td>0.416789</td>\n","      <td>0.445009</td>\n","      <td>0.150464</td>\n","      <td>5.021300</td>\n","      <td>2.221390</td>\n","      <td>-0.072333</td>\n","      <td>-0.215874</td>\n","      <td>1.56236</td>\n","      <td>0.074881</td>\n","      <td>0.010050</td>\n","      <td>0.018582</td>\n","      <td>0.067466</td>\n","      <td>5.578300</td>\n","      <td>3.085560</td>\n","      <td>3.842470</td>\n","      <td>0.011125</td>\n","      <td>2.35997</td>\n","      <td>0.695092</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>7.101993</td>\n","      <td>58.157021</td>\n","      <td>3374.306641</td>\n","      <td>4149.764648</td>\n","      <td>4149.764648</td>\n","      <td>32.237778</td>\n","      <td>0.430899</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.008602</td>\n","      <td>0.505536</td>\n","      <td>-100.098999</td>\n","      <td>3.012670</td>\n","      <td>0.027199</td>\n","      <td>1.194610</td>\n","      <td>5.036620</td>\n","      <td>2.517440</td>\n","      <td>4.553890</td>\n","      <td>0.063876</td>\n","      <td>0.337257</td>\n","      <td>4.439690</td>\n","      <td>0.013188</td>\n","      <td>3.379010</td>\n","      <td>3.38470</td>\n","      <td>1.167400</td>\n","      <td>2.246550</td>\n","      <td>1.750170</td>\n","      <td>2.76624</td>\n","      <td>-0.058501</td>\n","      <td>0.012595</td>\n","      <td>0.036144</td>\n","      <td>0.769057</td>\n","      <td>0.017496</td>\n","      <td>0.050283</td>\n","      <td>0.324697</td>\n","      <td>4.948640</td>\n","      <td>0.124789</td>\n","      <td>0.347128</td>\n","      <td>1.24512</td>\n","      <td>0.035822</td>\n","      <td>-0.013188</td>\n","      <td>0.023194</td>\n","      <td>0.006444</td>\n","      <td>4.983330</td>\n","      <td>23.706900</td>\n","      <td>8.287290</td>\n","      <td>4.796230</td>\n","      <td>1.79928</td>\n","      <td>-0.050040</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.551832</td>\n","      <td>10.509767</td>\n","      <td>110.333733</td>\n","      <td>176.578537</td>\n","      <td>176.578537</td>\n","      <td>28.490255</td>\n","      <td>0.394878</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.461000</td>\n","      <td>2.437260</td>\n","      <td>-112.963997</td>\n","      <td>3.541230</td>\n","      <td>0.752338</td>\n","      <td>4.338310</td>\n","      <td>1.648080</td>\n","      <td>4.699910</td>\n","      <td>1.950250</td>\n","      <td>0.005303</td>\n","      <td>2.071680</td>\n","      <td>0.546499</td>\n","      <td>0.141781</td>\n","      <td>1.673170</td>\n","      <td>4.30649</td>\n","      <td>1.702330</td>\n","      <td>-0.062869</td>\n","      <td>1.619230</td>\n","      <td>4.19053</td>\n","      <td>0.055140</td>\n","      <td>-0.016590</td>\n","      <td>0.017805</td>\n","      <td>3.064810</td>\n","      <td>0.070370</td>\n","      <td>0.098316</td>\n","      <td>3.507540</td>\n","      <td>1.069100</td>\n","      <td>0.012750</td>\n","      <td>0.009981</td>\n","      <td>3.46781</td>\n","      <td>0.035920</td>\n","      <td>-0.009804</td>\n","      <td>0.065728</td>\n","      <td>-0.004725</td>\n","      <td>5.281020</td>\n","      <td>11.528800</td>\n","      <td>0.171694</td>\n","      <td>4.394570</td>\n","      <td>2.52084</td>\n","      <td>0.079365</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.224444</td>\n","      <td>11.536294</td>\n","      <td>133.022888</td>\n","      <td>167.228073</td>\n","      <td>167.228073</td>\n","      <td>25.425522</td>\n","      <td>0.278908</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.140556</td>\n","      <td>3.085610</td>\n","      <td>179.451004</td>\n","      <td>0.573945</td>\n","      <td>0.057342</td>\n","      <td>2.216790</td>\n","      <td>1.623480</td>\n","      <td>0.526174</td>\n","      <td>1.542540</td>\n","      <td>-0.026160</td>\n","      <td>1.609440</td>\n","      <td>1.723560</td>\n","      <td>-0.019564</td>\n","      <td>1.552130</td>\n","      <td>4.83264</td>\n","      <td>1.501640</td>\n","      <td>0.192669</td>\n","      <td>4.614890</td>\n","      <td>1.47069</td>\n","      <td>-0.010031</td>\n","      <td>0.072805</td>\n","      <td>0.048035</td>\n","      <td>3.230210</td>\n","      <td>-0.031548</td>\n","      <td>0.028697</td>\n","      <td>3.752520</td>\n","      <td>4.948470</td>\n","      <td>-0.174542</td>\n","      <td>-0.033491</td>\n","      <td>2.47823</td>\n","      <td>0.068130</td>\n","      <td>0.090797</td>\n","      <td>0.029877</td>\n","      <td>0.146718</td>\n","      <td>3.169830</td>\n","      <td>-12.984600</td>\n","      <td>3.135210</td>\n","      <td>1.765010</td>\n","      <td>3.25399</td>\n","      <td>0.713238</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.714848</td>\n","      <td>17.870302</td>\n","      <td>318.437653</td>\n","      <td>610.507568</td>\n","      <td>610.507568</td>\n","      <td>36.194351</td>\n","      <td>0.182896</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.128876</td>\n","      <td>5.199760</td>\n","      <td>107.466003</td>\n","      <td>-0.497149</td>\n","      <td>0.080220</td>\n","      <td>0.458121</td>\n","      <td>0.629839</td>\n","      <td>5.240460</td>\n","      <td>-0.232279</td>\n","      <td>0.030006</td>\n","      <td>0.481359</td>\n","      <td>2.176020</td>\n","      <td>0.193162</td>\n","      <td>1.392090</td>\n","      <td>2.51890</td>\n","      <td>2.993170</td>\n","      <td>4.170910</td>\n","      <td>0.318375</td>\n","      <td>4.84563</td>\n","      <td>0.085064</td>\n","      <td>0.026443</td>\n","      <td>-0.004559</td>\n","      <td>0.120327</td>\n","      <td>-0.008630</td>\n","      <td>0.004495</td>\n","      <td>4.921700</td>\n","      <td>1.685640</td>\n","      <td>0.095628</td>\n","      <td>0.189131</td>\n","      <td>2.56955</td>\n","      <td>0.046643</td>\n","      <td>0.111462</td>\n","      <td>0.002912</td>\n","      <td>0.060737</td>\n","      <td>4.253000</td>\n","      <td>38.703400</td>\n","      <td>0.170825</td>\n","      <td>-0.598784</td>\n","      <td>3.92796</td>\n","      <td>0.262956</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.540107</td>\n","      <td>11.305001</td>\n","      <td>127.290840</td>\n","      <td>395.146667</td>\n","      <td>395.146667</td>\n","      <td>41.474819</td>\n","      <td>0.181556</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>539995</th>\n","      <td>0.431599</td>\n","      <td>1.507560</td>\n","      <td>24.269800</td>\n","      <td>2.928480</td>\n","      <td>2.788830</td>\n","      <td>5.152330</td>\n","      <td>2.779980</td>\n","      <td>0.816389</td>\n","      <td>4.791560</td>\n","      <td>0.026331</td>\n","      <td>4.562970</td>\n","      <td>0.233379</td>\n","      <td>0.254225</td>\n","      <td>2.213830</td>\n","      <td>5.58360</td>\n","      <td>3.800710</td>\n","      <td>0.503562</td>\n","      <td>4.061380</td>\n","      <td>2.75466</td>\n","      <td>0.112982</td>\n","      <td>-0.038411</td>\n","      <td>0.077714</td>\n","      <td>3.010950</td>\n","      <td>-0.008242</td>\n","      <td>0.043315</td>\n","      <td>0.080434</td>\n","      <td>2.371080</td>\n","      <td>0.133727</td>\n","      <td>0.355986</td>\n","      <td>2.01470</td>\n","      <td>0.002188</td>\n","      <td>0.220446</td>\n","      <td>0.078856</td>\n","      <td>0.084574</td>\n","      <td>0.758547</td>\n","      <td>-3.627310</td>\n","      <td>2.367110</td>\n","      <td>0.179322</td>\n","      <td>1.25804</td>\n","      <td>0.029282</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.660959</td>\n","      <td>3.002872</td>\n","      <td>8.945618</td>\n","      <td>179.705383</td>\n","      <td>179.705383</td>\n","      <td>48.332188</td>\n","      <td>0.457981</td>\n","    </tr>\n","    <tr>\n","      <th>539996</th>\n","      <td>0.069713</td>\n","      <td>2.355480</td>\n","      <td>-128.755005</td>\n","      <td>2.721580</td>\n","      <td>1.256300</td>\n","      <td>4.248220</td>\n","      <td>2.014550</td>\n","      <td>2.207120</td>\n","      <td>3.020260</td>\n","      <td>0.020398</td>\n","      <td>4.588860</td>\n","      <td>3.219260</td>\n","      <td>-0.011444</td>\n","      <td>2.802410</td>\n","      <td>1.71392</td>\n","      <td>4.173030</td>\n","      <td>-0.028895</td>\n","      <td>2.029860</td>\n","      <td>1.67972</td>\n","      <td>0.059944</td>\n","      <td>0.052139</td>\n","      <td>-0.006159</td>\n","      <td>2.235450</td>\n","      <td>0.105783</td>\n","      <td>0.091785</td>\n","      <td>4.098640</td>\n","      <td>0.232705</td>\n","      <td>0.173007</td>\n","      <td>0.180720</td>\n","      <td>3.94704</td>\n","      <td>0.211080</td>\n","      <td>0.034419</td>\n","      <td>0.077198</td>\n","      <td>0.027838</td>\n","      <td>1.180220</td>\n","      <td>-3.170320</td>\n","      <td>-0.545938</td>\n","      <td>3.045400</td>\n","      <td>2.23775</td>\n","      <td>0.458355</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>-0.041132</td>\n","      <td>13.038609</td>\n","      <td>169.999344</td>\n","      <td>178.883606</td>\n","      <td>178.883606</td>\n","      <td>24.497311</td>\n","      <td>0.267225</td>\n","    </tr>\n","    <tr>\n","      <th>539997</th>\n","      <td>0.385075</td>\n","      <td>2.528890</td>\n","      <td>-63.985401</td>\n","      <td>0.975396</td>\n","      <td>0.043852</td>\n","      <td>0.829423</td>\n","      <td>2.014210</td>\n","      <td>1.509500</td>\n","      <td>2.027590</td>\n","      <td>0.097387</td>\n","      <td>3.425350</td>\n","      <td>1.195470</td>\n","      <td>0.090862</td>\n","      <td>-0.130309</td>\n","      <td>5.42106</td>\n","      <td>1.561510</td>\n","      <td>0.132260</td>\n","      <td>0.392255</td>\n","      <td>5.08088</td>\n","      <td>-0.059632</td>\n","      <td>0.074616</td>\n","      <td>0.089685</td>\n","      <td>4.798180</td>\n","      <td>0.092356</td>\n","      <td>0.014446</td>\n","      <td>3.729750</td>\n","      <td>1.649350</td>\n","      <td>-0.005483</td>\n","      <td>0.326276</td>\n","      <td>2.88960</td>\n","      <td>0.067742</td>\n","      <td>0.028514</td>\n","      <td>0.074359</td>\n","      <td>0.070743</td>\n","      <td>1.646070</td>\n","      <td>29.165400</td>\n","      <td>0.364036</td>\n","      <td>4.478340</td>\n","      <td>3.64816</td>\n","      <td>0.647542</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.822070</td>\n","      <td>7.245872</td>\n","      <td>52.387405</td>\n","      <td>142.662323</td>\n","      <td>142.662323</td>\n","      <td>34.947292</td>\n","      <td>0.510507</td>\n","    </tr>\n","    <tr>\n","      <th>539998</th>\n","      <td>1.846240</td>\n","      <td>3.415350</td>\n","      <td>26.847601</td>\n","      <td>-0.120134</td>\n","      <td>0.027113</td>\n","      <td>2.155160</td>\n","      <td>2.529860</td>\n","      <td>2.502250</td>\n","      <td>3.453090</td>\n","      <td>0.090760</td>\n","      <td>1.307160</td>\n","      <td>4.107690</td>\n","      <td>0.034657</td>\n","      <td>0.867694</td>\n","      <td>1.60534</td>\n","      <td>2.978230</td>\n","      <td>0.145505</td>\n","      <td>2.855640</td>\n","      <td>1.13562</td>\n","      <td>0.138793</td>\n","      <td>-0.005488</td>\n","      <td>0.012881</td>\n","      <td>0.576931</td>\n","      <td>0.015822</td>\n","      <td>0.120977</td>\n","      <td>1.147820</td>\n","      <td>0.252155</td>\n","      <td>0.202905</td>\n","      <td>0.125948</td>\n","      <td>3.66790</td>\n","      <td>0.092273</td>\n","      <td>-0.005253</td>\n","      <td>0.029498</td>\n","      <td>0.110625</td>\n","      <td>2.201660</td>\n","      <td>13.295000</td>\n","      <td>0.181733</td>\n","      <td>1.299380</td>\n","      <td>1.48190</td>\n","      <td>0.229645</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.476450</td>\n","      <td>3.194854</td>\n","      <td>10.134982</td>\n","      <td>162.451324</td>\n","      <td>162.451324</td>\n","      <td>47.713188</td>\n","      <td>0.192319</td>\n","    </tr>\n","    <tr>\n","      <th>539999</th>\n","      <td>0.475802</td>\n","      <td>2.670740</td>\n","      <td>389.761993</td>\n","      <td>4.690200</td>\n","      <td>0.069227</td>\n","      <td>5.451320</td>\n","      <td>0.861476</td>\n","      <td>0.854981</td>\n","      <td>5.315200</td>\n","      <td>0.119477</td>\n","      <td>1.972080</td>\n","      <td>3.979380</td>\n","      <td>0.369296</td>\n","      <td>3.342400</td>\n","      <td>2.76147</td>\n","      <td>3.250500</td>\n","      <td>0.056835</td>\n","      <td>4.989740</td>\n","      <td>2.12784</td>\n","      <td>0.062638</td>\n","      <td>0.060752</td>\n","      <td>0.088188</td>\n","      <td>2.084750</td>\n","      <td>0.033652</td>\n","      <td>0.099527</td>\n","      <td>3.948260</td>\n","      <td>2.820770</td>\n","      <td>0.232900</td>\n","      <td>0.075716</td>\n","      <td>3.44848</td>\n","      <td>0.058991</td>\n","      <td>0.058473</td>\n","      <td>0.022776</td>\n","      <td>0.008793</td>\n","      <td>2.960360</td>\n","      <td>20.688499</td>\n","      <td>-0.359104</td>\n","      <td>3.013510</td>\n","      <td>-0.14368</td>\n","      <td>-0.008140</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>5.357403</td>\n","      <td>38.718704</td>\n","      <td>1495.206543</td>\n","      <td>2075.022949</td>\n","      <td>2075.022949</td>\n","      <td>33.248550</td>\n","      <td>0.276711</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>540000 rows × 207 columns</p>\n","</div>"],"text/plain":["              f0        f1          f2  ...          max       kurt  quantile\n","0       0.003229  4.838660  585.528992  ...  4149.764648  32.237778  0.430899\n","1       0.008602  0.505536 -100.098999  ...   176.578537  28.490255  0.394878\n","2       1.461000  2.437260 -112.963997  ...   167.228073  25.425522  0.278908\n","3       0.140556  3.085610  179.451004  ...   610.507568  36.194351  0.182896\n","4       0.128876  5.199760  107.466003  ...   395.146667  41.474819  0.181556\n","...          ...       ...         ...  ...          ...        ...       ...\n","539995  0.431599  1.507560   24.269800  ...   179.705383  48.332188  0.457981\n","539996  0.069713  2.355480 -128.755005  ...   178.883606  24.497311  0.267225\n","539997  0.385075  2.528890  -63.985401  ...   142.662323  34.947292  0.510507\n","539998  1.846240  3.415350   26.847601  ...   162.451324  47.713188  0.192319\n","539999  0.475802  2.670740  389.761993  ...  2075.022949  33.248550  0.276711\n","\n","[540000 rows x 207 columns]"]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","metadata":{"id":"njGTQ_2OHQ0w"},"source":["# Model10-DNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWL-uGqZI5iQ","executionInfo":{"status":"ok","timestamp":1637162157186,"user_tz":-540,"elapsed":4604942,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"dfe63fb9-a7bd-4266-84b7-8aac7a1b9904"},"source":["FOLD = 5\n","VERBOSE = 0\n","SEEDS = [2021, 2025]\n","BATCH_SIZE = 512\n","\n","counter = 0\n","oof_score = 0\n","y_pred_final_dnn = np.zeros((test_df.shape[0], 1))\n","y_pred_meta_dnn = np.zeros((train_df.shape[0], 1))\n","\n","\n","for sidx, seed in enumerate(SEEDS):\n","    seed_score = 0\n","    \n","    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n","\n","    for idx, (train, val) in enumerate(kfold.split(train_df[features], train_df['target'])):\n","        counter += 1\n","\n","        train_x, train_y = train_df[features].iloc[train], train_df['target'].iloc[train]\n","        val_x, val_y = train_df[features].iloc[val], train_df['target'].iloc[val]\n","\n","        model7 = dnn_model()\n","        model7.compile(optimizer=Adam(learning_rate=1e-2), \n","                      loss=\"binary_crossentropy\", \n","                      metrics=['AUC'])\n","\n","        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n","                               patience=4, verbose=VERBOSE)\n","        \n","        chk_point = ModelCheckpoint(f'./Keras_DNN_Model_{counter}C.h5', \n","                                    monitor='val_loss', verbose=VERBOSE, \n","                                    save_best_only=True, mode='min')\n","\n","        es = EarlyStopping(monitor=\"val_loss\", patience=15, \n","                           verbose=VERBOSE, mode=\"min\", \n","                           restore_best_weights=True)\n","        \n","        model7.fit(train_x, train_y, \n","                  validation_data=(val_x, val_y), \n","                  epochs=300,\n","                  verbose=VERBOSE,\n","                  batch_size=BATCH_SIZE, \n","                  callbacks=[lr, chk_point, es])\n","        \n","        model7 = load_model(f'./Keras_DNN_Model_{counter}C.h5')\n","        \n","        y_pred = model7.predict(val_x, batch_size=BATCH_SIZE)\n","        y_pred_meta_dnn[val] += y_pred\n","        y_pred_final_dnn += model7.predict(test_df, batch_size=BATCH_SIZE)\n","        \n","        score = roc_auc_score(val_y, y_pred)\n","        oof_score += score\n","        seed_score += score\n","        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n","        \n","        del model7, y_pred\n","        del train_x, train_y\n","        del val_x, val_y\n","        gc.collect()\n","    \n","    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n","\n","\n","y_pred_meta_dnn7 = y_pred_meta_dnn / float(len(SEEDS))\n","y_pred_final_dnn7 = y_pred_final_dnn / float(counter)\n","oof_score /= float(counter)\n","print(\"Aggregate OOF Score: {}\".format(oof_score))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-0 | OOF Score: 0.744060517545417\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-1 | OOF Score: 0.7488193638908178\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-2 | OOF Score: 0.7447349246522129\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-3 | OOF Score: 0.7486394165174783\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2021 | Fold-4 | OOF Score: 0.7520500681021389\n","\n","\n","Seed: 2021 | Aggregate OOF Score: 0.747660858141613\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-0 | OOF Score: 0.7461143771788741\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-1 | OOF Score: 0.7495787028451294\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-2 | OOF Score: 0.7494473348477763\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-3 | OOF Score: 0.7485224330972622\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Seed-2025 | Fold-4 | OOF Score: 0.7518934219473795\n","\n","\n","Seed: 2025 | Aggregate OOF Score: 0.7491112539832844\n","\n","\n","Aggregate OOF Score: 0.7483860560624487\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8H56_LpxI5iQ","executionInfo":{"status":"ok","timestamp":1637162159326,"user_tz":-540,"elapsed":1257,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"ef81ebfd-8ae5-4e3a-bac0-7cc68f492fcc"},"source":["y_pred_meta = np.mean(y_pred_meta_dnn7, axis=1)\n","y_pred = (y_pred_meta>0.5).astype(int)\n","print(classification_report(train_df['target'], y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.73      0.73      0.73    296394\n","           1       0.74      0.74      0.74    303606\n","\n","    accuracy                           0.73    600000\n","   macro avg       0.73      0.73      0.73    600000\n","weighted avg       0.73      0.73      0.73    600000\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"9Rs84ie7I5iQ","executionInfo":{"status":"ok","timestamp":1637162159327,"user_tz":-540,"elapsed":7,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"c32bba23-1448-4d12-9796-0d159bd23c6c"},"source":["cnf_matrix = confusion_matrix(train_df['target'], y_pred, labels=[0, 1])\n","np.set_printoptions(precision=2)\n","plt.figure(figsize=(12, 5))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{},"execution_count":69},{"output_type":"display_data","data":{"text/plain":["<Figure size 864x360 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"9DSljIN9I5iQ","executionInfo":{"status":"ok","timestamp":1637162160828,"user_tz":-540,"elapsed":1505,"user":{"displayName":"영찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08284490542508903619"}},"outputId":"c5460167-c8c6-4397-dd34-2758066ca69b"},"source":["submit_df7 = pd.read_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/sample_submission.csv\")\n","submit_df7['target'] = y_pred_final_dnn7.ravel()\n","submit_df7.to_csv(\"/content/drive/MyDrive/AI/dataset/tabular-playground-series-nov-2021/Derived_data.csv\", index=False)\n","submit_df7.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>600000</td>\n","      <td>0.723546</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>600001</td>\n","      <td>0.732156</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>600002</td>\n","      <td>0.739589</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>600003</td>\n","      <td>0.479302</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>600004</td>\n","      <td>0.721516</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id    target\n","0  600000  0.723546\n","1  600001  0.732156\n","2  600002  0.739589\n","3  600003  0.479302\n","4  600004  0.721516"]},"metadata":{},"execution_count":70}]}]}